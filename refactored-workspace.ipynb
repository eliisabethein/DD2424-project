{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "HpqqiuiZbZLn",
    "outputId": "4feaa888-53de-480d-d7d3-e2ffd7ad7a2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/eliisabethein/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions.normal as normal\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "import csv\n",
    "from gensim.models import Word2Vec\n",
    "import os.path\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.style.use('seaborn-bright')\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqN4walGbZLr"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cSKWwvR2bZLu"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6k0Znrz6bZLu"
   },
   "outputs": [],
   "source": [
    "def load_data(filename, max_sentence_len, with_labels=False):\n",
    "    # the tokenizer splits <unk> so we use MWETokenizer to re-merge it\n",
    "    data_original = []\n",
    "    data_padded = []\n",
    "    with open(filename, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            sentence, padded_sentence = tokenize_sentence(line, max_sentence_len, with_labels)\n",
    "            data_original.append(sentence)\n",
    "            data_padded.append(padded_sentence)\n",
    "    \n",
    "    return data_original, data_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tRPRgIpbZLx"
   },
   "outputs": [],
   "source": [
    "def tokenize_sentence(string, max_sentence_len, with_labels=False, occurrences=None):\n",
    "    merger = MWETokenizer([('<', 'unk', '>')], separator = '') \n",
    "    sentence = word_tokenize(string.strip())       # tokenize sentence\n",
    "    sentence = merger.tokenize(sentence)         # merge <unk>\n",
    "    if with_labels:\n",
    "        sentence = sentence[1:]\n",
    "    sentence = [token.lower() for token in sentence]            \n",
    "    sentence = sentence[:max_sentence_len - 2]   # cut sentence at max_sentence_length    \n",
    "    sentence = ['<sos>'] + sentence + ['<eos>']  # add start and end-of-sentence tags\n",
    "    if occurrences is not None:\n",
    "        for word in sentence:\n",
    "            if word in occurrences:\n",
    "                occurrences[word] += 1\n",
    "            else:\n",
    "                occurrences[word] = 1\n",
    "\n",
    "    # pad the rest of the sentence\n",
    "    padded_sentence = sentence.copy()\n",
    "    padded_sentence.extend(['<pad>']*(max_sentence_len - len(sentence))) \n",
    "    \n",
    "    if occurrences is not None:\n",
    "        return sentence, padded_sentence, occurrences\n",
    "    else:\n",
    "        return sentence, padded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50fGsen8bZL0"
   },
   "outputs": [],
   "source": [
    "def get_batches_text(data, data_padded, batch_size, pad_index, word2vec_model, unk_word='<unk>'):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    lengths = []\n",
    "    for i in range(len(data) // batch_size):\n",
    "        # take batch_size sentences from the data each time\n",
    "        batch_sentences = data[i*batch_size:(i+1)*batch_size]\n",
    "        batch_sentence_lens = [len(x) for x in batch_sentences]\n",
    "        \n",
    "        # sentences in a batch have to be sorted in decreasing order of length (for pack_padded_sentence)\n",
    "        sorted_pairs = sorted(zip(batch_sentence_lens,batch_sentences), reverse=True)\n",
    "        batch_sentences = [sentence for length, sentence in sorted_pairs]\n",
    "        batch_sentence_lens = [length-1 for length, sentence in sorted_pairs]\n",
    "        \n",
    "        # each input and target is a (batch_size x max_sentence_len-1 x 1) matrix\n",
    "        # initially filled with the index for padditng tag <pad>\n",
    "        input_batch = np.ones((batch_size, len(data_padded[0])-1, 1)) * pad_index\n",
    "        target_batch = np.ones((batch_size, len(data_padded[0])-1, 1)) * pad_index\n",
    "        \n",
    "        # for each sentence in the batch, fill the corresponding row in current_batch\n",
    "        # with the indexed of the words in the sentence (except for <pad>)\n",
    "        for j, sentence in enumerate(batch_sentences):\n",
    "            word_indexes = np.array([word2vec_model.wv.vocab[word].index if word in word2vec_model.wv.vocab else word2vec_model.wv.vocab[unk_word].index for word in sentence])\n",
    "            input_batch[j,0:len(sentence)-1,0] = word_indexes[:-1]\n",
    "            target_batch[j,0:len(sentence)-1,0] = word_indexes[1:]\n",
    "        \n",
    "        # make the matrices into torch tensors and append\n",
    "        inputs.append(input_batch)\n",
    "        targets.append(target_batch)\n",
    "        lengths.append(batch_sentence_lens)\n",
    "    return inputs, targets, lengths\n",
    "\n",
    "def get_batches_synthetic(data, batch_size):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(data) // batch_size):\n",
    "        batch_sentences = data[i * batch_size:(i+1) * batch_size]\n",
    "\n",
    "        input_batch = np.ones((batch_size, data.shape[1] - 1, 1)) \n",
    "        target_batch = np.ones((batch_size, data.shape[1] - 1, 1)) \n",
    "        for j, sentence in enumerate(batch_sentences):\n",
    "                input_batch[j,0:len(sentence)-1,0] = sentence[:-1]\n",
    "                target_batch[j,0:len(sentence)-1,0] = sentence[1:]\n",
    "        inputs.append(input_batch)\n",
    "        targets.append(target_batch)\n",
    "    \n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTfmo5X7bZMB"
   },
   "source": [
    "### Encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJRr0EEBbZMB"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, embedding_weights, synthetic=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        # parameters\n",
    "        self.embedding_size = embedding_weights.shape[1]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = True\n",
    "        \n",
    "        #layers\n",
    "        self.embed = nn.Embedding.from_pretrained(embedding_weights)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, batch_first=self.batch_first)\n",
    "        \n",
    "    def forward(self, x, hidden, x_lens=None, train=True):\n",
    "        batch_size, max_len, _ = x.shape\n",
    "        \n",
    "        x = torch.tensor(x, dtype=torch.long)  # make the input into a torch tensor\n",
    "        x = self.embed(x).view(batch_size, max_len, self.embedding_size)\n",
    "\n",
    "        if x_lens is not None and train:\n",
    "            x_lens = torch.tensor(x_lens, dtype=torch.long)\n",
    "            x = pack_padded_sequence(x, x_lens, batch_first=self.batch_first)\n",
    "            \n",
    "        output, hidden = self.lstm(x.float(), hidden) \n",
    "\n",
    "        if x_lens is not None and train:\n",
    "            output, output_lens = pad_packed_sequence(output, batch_first=self.batch_first, \n",
    "                                                      total_length=max_sentence_length-1)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        c = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plSlS-fubZME"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,hidden_size, num_layers, embedding_weights, synthetic=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        # parameters\n",
    "        self.vocabulary_size = embedding_weights.shape[0]\n",
    "        self.embedding_size = embedding_weights.shape[1]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = True\n",
    "        \n",
    "        # layers\n",
    "        self.embed = nn.Embedding.from_pretrained(embedding_weights)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, batch_first=self.batch_first)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.vocabulary_size)\n",
    "\n",
    "    def forward(self, x, hidden, x_lens=None, train=True):\n",
    "        batch_size, max_len, _ = x.shape\n",
    "        \n",
    "        x = torch.tensor(x, dtype=torch.long)  # make the input into a torch tensor\n",
    "        x = self.embed(x).view(batch_size, max_len, self.embedding_size)\n",
    "        \n",
    "        if x_lens is not None and train:\n",
    "            x_lens = torch.tensor(x_lens, dtype=torch.long)\n",
    "            x = pack_padded_sequence(x, x_lens, batch_first=self.batch_first)\n",
    "\n",
    "        output, hidden = self.lstm(x.float(), hidden) \n",
    "        \n",
    "        if x_lens is not None and train:\n",
    "            output, output_lens = pad_packed_sequence(output, batch_first=self.batch_first, \n",
    "                                                      total_length=max_sentence_length-1)\n",
    "        \n",
    "        output = output.reshape(output.size(0)*output.size(1), output.size(2))\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGTiY8OzbZMG"
   },
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVeJWdxDbZMJ"
   },
   "outputs": [],
   "source": [
    "class StochasticEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, latent_dim, synthetic=False):\n",
    "        super(StochasticEncoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_first = True\n",
    "        \n",
    "        self.hidden_to_mean = nn.Linear(2 * self.hidden_dim * num_layers, self.latent_dim, self.batch_first)\n",
    "        self.hidden_to_logvar = nn.Linear(2 * self.hidden_dim * num_layers, self.latent_dim, self.batch_first)\n",
    "\n",
    "    def reparametrize(self, mean, log_variance):\n",
    "        eps = torch.randn_like(mean)\n",
    "        return mean + eps * torch.exp(0.5 * log_variance)\n",
    "        \n",
    "    def forward(self, hidden_concatenated):\n",
    "        mean = self.hidden_to_mean(hidden_concatenated)\n",
    "        log_variance = self.hidden_to_logvar(hidden_concatenated)\n",
    "        z = self.reparametrize(mean, log_variance)\n",
    "        return z, mean, log_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWVMhlE_bZMK"
   },
   "outputs": [],
   "source": [
    "class StochasticDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, latent_dim, synthetic=False):\n",
    "        super(StochasticDecoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_first = True\n",
    "        \n",
    "        self.latent_to_hidden = nn.Linear(latent_dim, 2 * self.hidden_dim * num_layers, self.batch_first)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        hidden_concatenated = self.latent_to_hidden(z)\n",
    "        return hidden_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pmtmMPFjbZMO"
   },
   "outputs": [],
   "source": [
    "# new VAE\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, embedding_weights, latent_dim, synthetic=False):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_first = True\n",
    "        \n",
    "        self.encoder = Encoder(self.hidden_dim, num_layers, embedding_weights, synthetic)\n",
    "        self.stochastic_encoder = StochasticEncoder(self.hidden_dim, num_layers, self.latent_dim, synthetic)\n",
    "        self.stochastic_decoder = StochasticDecoder(self.hidden_dim, num_layers, self.latent_dim, synthetic)\n",
    "        self.decoder = Decoder(self.hidden_dim, num_layers, embedding_weights, synthetic)\n",
    "        \n",
    "        # THIS PART IS IMPORTANT -- I think it re-initialises all of the weights in the network with\n",
    "        ## this distribution, even the embedding weights, which we initialised to (-0.1,0.1) before;\n",
    "        ## with this distribution it (kind of) works both without annealing and with annealing \n",
    "        ## (why??? who knows)\n",
    "        if synthetic:          \n",
    "            for param in self.parameters():\n",
    "                nn.init.uniform_(param, -0.01, 0.01)\n",
    "            nn.init.uniform_(self.encoder.embed.weight, -0.1, 0.1)\n",
    "            nn.init.uniform_(self.decoder.embed.weight, -0.1, 0.1)\n",
    "        \n",
    "    def encode(self, x, x_lens=None):\n",
    "        batch_size, max_len, _ = x.shape\n",
    "        hidden = self.encoder.init_hidden(batch_size)\n",
    "        _, hidden = self.encoder.forward(x, hidden, x_lens)\n",
    "        return hidden\n",
    "    \n",
    "    def latent_to_hidden(self, z):\n",
    "        return self.stochastic_decoder.latent_to_hidden(z)\n",
    "        \n",
    "    # with teacher forcing\n",
    "    def decode(self, hidden, x, x_lens=None, train=True): \n",
    "        outputs, _ = self.decoder.forward(x, hidden, x_lens, train)\n",
    "        return outputs\n",
    "    \n",
    "    def forward(self, x, x_lens=None, dropout_rate=0, unk_index=0):\n",
    "        hidden = self.encode(x, x_lens)\n",
    "        hidden_concatenated = torch.cat((hidden[0], hidden[1]), 2)\n",
    "        z, mean, log_variance = self.stochastic_encoder.forward(hidden_concatenated)\n",
    "        hidden_concatenated = self.stochastic_decoder.forward(z)\n",
    "        hidden = torch.split(hidden_concatenated, self.hidden_dim, dim=2)\n",
    "        \n",
    "        # word dropout\n",
    "        if dropout_rate != 0.0:\n",
    "            drop_probs = np.random.random_sample(x.shape)\n",
    "            drop_probs[:, 0] = 1                  # set the <sos> token to 1 (always keep)\n",
    "            for i, x_len in enumerate(x_lens):\n",
    "                drop_probs[i, x_len:, 0] = 1      # set the <pad> tokens to 1 (always keep)\n",
    "            dropped_x = x.copy()\n",
    "            dropped_x[drop_probs < dropout_rate] = unk_index\n",
    "            outputs = self.decode(hidden, dropped_x, x_lens)\n",
    "        else:\n",
    "            outputs = self.decode(hidden, x, x_lens)\n",
    "            \n",
    "        return mean, log_variance, outputs\n",
    "    \n",
    "    def calc_mi(self, x):\n",
    "        # I(x, z) = E_xE_{q(z|x)}log(q(z|x)) - E_xE_{q(z|x)}log(q(z))\n",
    "        mean, log_variance, _ = self.forward(x)\n",
    "        _, batch_size, _ = mean.size()\n",
    "\n",
    "        # E_{q(z|x)}log(q(z|x)) = -0.5*nz*log(2*\\pi) - 0.5*(1+logvar).sum(-1)\n",
    "        neg_entropy = (-0.5 * self.latent_dim * np.log(2 * np.pi)- 0.5 * (1 + log_variance).sum(-1)).mean()\n",
    "\n",
    "        z = self.stochastic_encoder.reparametrize(mean, log_variance)\n",
    "        mean, log_variance = mean.unsqueeze(0), log_variance.unsqueeze(0)\n",
    "\n",
    "        log_density = -0.5 * (((z - mean) ** 2) / log_variance.exp()).sum(dim=-1) - \\\n",
    "            0.5 * (self.latent_dim * np.log(2 * np.pi) + log_variance.sum(-1))\n",
    "\n",
    "        log_qz = log_sum_exp(log_density, dim=1) - np.log(batch_size)\n",
    "\n",
    "        return (neg_entropy - log_qz.mean(-1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "11ksRu_ibZMV"
   },
   "outputs": [],
   "source": [
    "def loss_function(outputs, labels, mean, log_variance, seq_length, annealing_args=None, mask=None):\n",
    "    if mask is not None:\n",
    "        BCE = torch.zeros(mean.shape[1] * (seq_length - 1))\n",
    "        BCE[mask] = nn.CrossEntropyLoss(reduction='none')(outputs, labels)\n",
    "    else:\n",
    "        BCE = nn.CrossEntropyLoss(reduction='none')(outputs, labels)\n",
    "    BCE = BCE.view(mean.shape[1], -1).sum(-1)\n",
    "    KLD = -0.5 * (1 + log_variance - mean.pow(2) - log_variance.exp()).permute(1, 0, 2).sum(-1).squeeze(-1)\n",
    "    if annealing_args is not None:\n",
    "        kl_weight = kl_annealing_weight(annealing_args['type'], annealing_args['step'], annealing_args['k'], annealing_args['first_step'])\n",
    "    else:\n",
    "        kl_weight = 1.0\n",
    "    weighted_KLD = kl_weight * KLD\n",
    "    loss = BCE + weighted_KLD\n",
    "    return loss, BCE, KLD, weighted_KLD, kl_weight\n",
    "    \n",
    "def kl_annealing_weight(annealing_type, step, k, first_step):\n",
    "    if annealing_type == 'logistic':\n",
    "        return float(1/(1+np.exp(-k*(step-first_step))))\n",
    "    elif annealing_type == 'linear':\n",
    "        return min(1, step/first_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interpolation_sequence(z1, z2, number_of_sentences_to_decode):\n",
    "    interpolations = np.zeros((z1.shape[0], number_of_sentences_to_decode + 2))\n",
    "    for dimension_of_z, (i, j) in enumerate(zip(z1, z2)):\n",
    "        interpolations[dimension_of_z] = np.linspace(i, j, number_of_sentences_to_decode + 2)    \n",
    "    return interpolations.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_PQofHPbZMZ"
   },
   "source": [
    "### True posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mLWcpwQbZMZ"
   },
   "outputs": [],
   "source": [
    "def log_sum_exp(value, dim=None, keepdim=False):\n",
    "    \"\"\"Numerically stable implementation of the operation\n",
    "    value.exp().sum(dim, keepdim).log() - copied from repo, we should change it\n",
    "    \"\"\"\n",
    "    if dim is not None:\n",
    "        m, _ = torch.max(value, dim=dim, keepdim=True)\n",
    "        value0 = value - m\n",
    "        if keepdim is False:\n",
    "            m = m.squeeze(dim)\n",
    "        return m + torch.log(torch.sum(torch.exp(value0), dim=dim, keepdim=keepdim))\n",
    "    else:\n",
    "        m = torch.max(value)\n",
    "        sum_exp = torch.sum(torch.exp(value - m))\n",
    "        return m + torch.log(sum_exp)\n",
    "\n",
    "def compute_true_posterior(latent_grid, vae, inputs, targets):\n",
    "    log_true_posterior = compute_true_log_posterior(latent_grid, vae, inputs, targets)\n",
    "    true_posterior = log_true_posterior.exp()\n",
    "    return true_posterior\n",
    "\n",
    "def compute_true_log_posterior(latent_grid, vae, inputs, targets):\n",
    "    latent_grid = latent_grid.unsqueeze(0).expand(inputs.shape[0], *latent_grid.size()).contiguous().permute(1, 0, 2)\n",
    "    \n",
    "    # Compute the true joint\n",
    "    log_true_joint = compute_true_joint(latent_grid, vae, inputs, targets)\n",
    "    \n",
    "    # Normalize by marginalizing z\n",
    "    log_true_posterior = log_true_joint - log_sum_exp(log_true_joint, dim=0, keepdim=True)\n",
    "    return log_true_posterior\n",
    "\n",
    "def compute_true_joint(latent_grid, vae, inputs, targets):\n",
    "    n_sample, batch_size, latent_dim = latent_grid.size()\n",
    "    seq_len = inputs.shape[1]\n",
    "    # Compute prior p(z)\n",
    "    normal = torch.distributions.normal.Normal(torch.zeros(latent_dim), torch.ones(latent_dim))\n",
    "    log_true_prior = normal.log_prob(latent_grid).sum(dim=-1)\n",
    "    \n",
    "    # Compute conditional p(x | z)\n",
    "    log_true_conditional = torch.zeros(latent_grid.size(0), latent_grid.size(1))\n",
    "    tensor_target_batch = torch.tensor(targets.reshape(-1), dtype=torch.long)\n",
    "    for i in range(latent_grid.size(0)):\n",
    "        hidden_concatenated = vae.latent_to_hidden(latent_grid[i]).unsqueeze(0)\n",
    "        hidden = torch.split(hidden_concatenated, vae.hidden_dim, dim=-1)\n",
    "        outputs = vae.decode(hidden, inputs, train=False)\n",
    "        log_true_conditional[i] = -nn.CrossEntropyLoss(reduction='none')(outputs, tensor_target_batch).view(batch_size, -1).sum(-1)\n",
    "        \n",
    "    # Compute joint p(x, z)\n",
    "    log_true_joint = log_true_prior + log_true_conditional\n",
    "    return log_true_joint\n",
    "\n",
    "def compute_true_posterior_mean(true_posterior, latent_grid):\n",
    "    return torch.mul(true_posterior.unsqueeze(2), latent_grid.unsqueeze(0)).sum(1)\n",
    "\n",
    "def generate_grid(lower, upper, step, dim=2):\n",
    "    line = torch.arange(lower, upper, step)\n",
    "    total_points = line.size(0)\n",
    "    if dim == 2:\n",
    "        z1 = line.unsqueeze(1).repeat(1, total_points).view(-1)\n",
    "        z2 = line.repeat(total_points)\n",
    "        return torch.cat((z1.unsqueeze(-1), z2.unsqueeze(-1)), dim=-1)\n",
    "    elif dim == 1:\n",
    "        return line.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P-MX0DvhbZMc"
   },
   "outputs": [],
   "source": [
    "def plot_mean_space(step, latent_size, vae, tracked_inputs, tracked_targets, lim=3, iteration=None):\n",
    "    latent_grid = generate_grid(-5, 5, step, latent_size)\n",
    "    true_posterior = compute_true_posterior(latent_grid, vae, tracked_inputs, tracked_targets)\n",
    "    true_mean = compute_true_posterior_mean(true_posterior.t(), latent_grid)\n",
    "    vae.eval()\n",
    "    approximate_mean, _, _ = vae.forward(tracked_inputs)\n",
    "    vae.train()\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(np.linspace(-1.5, 1.5, 100), np.linspace(-1.5, 1.5, 100), color='silver', linestyle='dashed', linewidth=1.0, zorder=1)\n",
    "    plt.scatter(true_mean.detach().numpy(), approximate_mean.detach().numpy(), marker='x', color='deepskyblue', s=15, zorder=2)\n",
    "    plt.xlim(-lim, lim)\n",
    "    plt.ylim(-lim, lim)\n",
    "    plt.xlabel(\"true posterior mean\")\n",
    "    plt.ylabel(\"approximate posterior mean\")\n",
    "    plt.savefig(\"plots/mean_space_iteration_{}.pdf\".format(iteration), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_kl(kl_terms, kl_weights):\n",
    "    plot_step = 10\n",
    "    x_axis = np.arange(len(kl_terms[::plot_step])) * plot_step\n",
    "    fig, ax1 = plt.subplots(figsize=(8,4))\n",
    "    ax1.plot(x_axis, kl_terms[::plot_step], label=\"KL term value\")\n",
    "    ax1.set_xlabel(\"iteration\")\n",
    "    ax1.set_ylabel(\"KL term\")\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x_axis, kl_weights[::plot_step], color=\"orange\", label=\"KL weight\")\n",
    "    ax2.set_ylabel(\"KL weight\")\n",
    "    ax2.set_ylim(0,1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_losses(total_loss, ce_loss, kl_loss):\n",
    "    plot_step = 10\n",
    "    x_axis = np.arange(len(total_loss[::plot_step])) * plot_step\n",
    "    total_loss = np.array(total_loss[::plot_step])\n",
    "    kl_loss = np.array(kl_loss[::plot_step])\n",
    "    fig, ax1 = plt.subplots(figsize=(8,4))\n",
    "    plt.fill_between(x_axis, np.zeros(len(x_axis)), total_loss, label=\"total loss\")\n",
    "    plt.fill_between(x_axis, np.zeros(len(x_axis)), kl_loss, label=\"kl loss\")\n",
    "    plt.xlabel(\"loss\")\n",
    "    plt.ylabel(\"iteration\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BvL2RqG8bZMd"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y04SeMISbZMe"
   },
   "outputs": [],
   "source": [
    "def train(vae, inputs, targets, validation_inputs, validation_targets, epochs, vocab_size, hidden_size, \n",
    "          latent_size, max_sentence_length, num_layers=1, learning_rate=0.001,\n",
    "          synthetic=False, input_lens=None, val_input_lens=None,               # text-related parameters\n",
    "          dropout_rate=0.0, unk_index = None,                                  # word dropout parameters\n",
    "          plot=False, plot_lim=1.5, step=1.0, tracked_inputs=None, tracked_targets=None,      # plotting\n",
    "          annealing_args=None, is_aggressive=False, verbose=True):\n",
    "    \n",
    "    opt_dict = {\"not_improved\": 0, \"lr\": learning_rate, \"best_loss\": 1e4}\n",
    "    \n",
    "    decay_epoch = 2\n",
    "    lr_decay = 0.5\n",
    "    max_decay = 5\n",
    "\n",
    "#     enc_optimizer = torch.optim.SGD(vae.encoder.parameters(), lr=learning_rate)\n",
    "#     stoch_enc_optimizer = torch.optim.SGD(vae.stochastic_encoder.parameters(), lr=learning_rate)\n",
    "#     stoch_dec_optimizer = torch.optim.SGD(vae.stochastic_decoder.parameters(), lr=learning_rate)\n",
    "#     dec_optimizer = torch.optim.SGD(vae.decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    enc_optimizer = torch.optim.Adam(vae.encoder.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "    stoch_enc_optimizer = torch.optim.Adam(vae.stochastic_encoder.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "    stoch_dec_optimizer = torch.optim.Adam(vae.stochastic_decoder.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "    dec_optimizer = torch.optim.Adam(vae.decoder.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "    \n",
    "    if annealing_args is not None:\n",
    "        kl_terms = []\n",
    "        kl_weights = []\n",
    "\n",
    "    iteration = decay_cnt = 0\n",
    "    total_losses = []\n",
    "    ce_losses = []\n",
    "    kl_losses = []\n",
    "    total_epoch_losses = []\n",
    "    val_total_epoch_losses = []\n",
    "    \n",
    "    if plot:\n",
    "        plot_mean_space(step, latent_size, vae, tracked_inputs, tracked_targets, lim=plot_lim, iteration=iteration)\n",
    "    \n",
    "    previous_mi = -1\n",
    "        \n",
    "    for epoch in range(epochs):        \n",
    "        for i in np.random.permutation(len(inputs)):\n",
    "            \n",
    "            inner_iter = 1\n",
    "            random_i = i\n",
    "            \n",
    "            burn_num_words = 0\n",
    "            burn_pre_loss = 1e4\n",
    "            burn_cur_loss = 0\n",
    "            while is_aggressive and inner_iter < 100:\n",
    "                x = inputs[random_i]\n",
    "                y = torch.tensor(targets[random_i].reshape(-1), dtype=torch.long)\n",
    "                x_lens = input_lens[random_i] if not synthetic else None\n",
    "                \n",
    "                enc_optimizer.zero_grad()\n",
    "                stoch_enc_optimizer.zero_grad()\n",
    "                stoch_dec_optimizer.zero_grad()\n",
    "                dec_optimizer.zero_grad()\n",
    "                \n",
    "                if synthetic:\n",
    "                    burn_batch_size, burn_sents_len, _ = x.shape\n",
    "                    burn_num_words += burn_sents_len * burn_batch_size\n",
    "                else:\n",
    "                    burn_num_words = np.sum(x_lens)\n",
    "                \n",
    "                mask = None\n",
    "                mean, log_variance, outputs = vae(x, x_lens=x_lens)\n",
    "                if not synthetic:\n",
    "                    mask = (y < padding_index)\n",
    "                    outputs = outputs[mask]\n",
    "                    y = y[mask]\n",
    "    \n",
    "                loss_summary = loss_function(outputs, y, mean, log_variance, max_sentence_length, annealing_args=annealing_args, mask=mask)\n",
    "                \n",
    "                loss = loss_summary[0]\n",
    "                burn_cur_loss += loss.sum().item()\n",
    "                \n",
    "                loss = loss.mean(dim=-1)\n",
    "                loss.backward()\n",
    "                \n",
    "                clip_grad_norm_(vae.parameters(), 5.0)\n",
    "                \n",
    "                stoch_enc_optimizer.step()\n",
    "                enc_optimizer.step()\n",
    "                \n",
    "                random_i = np.random.randint(0, len(inputs)- 1)\n",
    "                if inner_iter % 15 == 0:\n",
    "                    burn_cur_loss = burn_cur_loss / burn_num_words\n",
    "                    if burn_pre_loss - burn_cur_loss < 0:\n",
    "                        break\n",
    "                    burn_pre_loss = burn_cur_loss\n",
    "                    burn_cur_loss = burn_num_words = 0\n",
    "                inner_iter += 1\n",
    "              \n",
    "            x = inputs[i]\n",
    "            y = torch.tensor(targets[i].reshape(-1), dtype=torch.long)\n",
    "            x_lens = input_lens[i] if not synthetic else None  \n",
    "            \n",
    "            mask = None\n",
    "            mean, log_variance, outputs = vae(x, x_lens=x_lens, dropout_rate=dropout_rate, unk_index=unk_index)\n",
    "\n",
    "            if not synthetic:\n",
    "                mask = (y < padding_index)\n",
    "                outputs = outputs[mask]\n",
    "                y = y[mask]\n",
    "            \n",
    "            enc_optimizer.zero_grad()\n",
    "            stoch_enc_optimizer.zero_grad()\n",
    "            stoch_dec_optimizer.zero_grad()\n",
    "            dec_optimizer.zero_grad()\n",
    "            \n",
    "            loss_summary = loss_function(outputs, y, mean, log_variance, max_sentence_length, annealing_args=annealing_args, mask=mask)\n",
    "            \n",
    "            total_losses.append(np.mean(loss_summary[0].data.numpy()))\n",
    "            ce_losses.append(np.mean(loss_summary[1].data.numpy()))\n",
    "            kl_losses.append(np.mean(loss_summary[3].data.numpy()))\n",
    "            \n",
    "            loss = loss_summary[0]\n",
    "                \n",
    "            loss = loss.mean(dim=-1)\n",
    "            \n",
    "            if annealing_args is not None:\n",
    "                kl_terms.append(np.mean(loss_summary[2].data.numpy()))\n",
    "                kl_weights.append(loss_summary[4])     \n",
    "            \n",
    "            loss.backward()\n",
    "            clip_grad_norm_(vae.parameters(), 5.0)\n",
    "            \n",
    "            if not is_aggressive:\n",
    "                stoch_enc_optimizer.step()\n",
    "                enc_optimizer.step()\n",
    "            \n",
    "            dec_optimizer.step()\n",
    "            stoch_dec_optimizer.step()\n",
    "\n",
    "            if (iteration % 100 == 0) and verbose:\n",
    "                print('epoch {} iteration {} loss {:.3f} CE {:.3f} KL {:.3f} weighted KL: {:.3f} weight {:.3f}'.format(epoch+1, \n",
    "                            iteration, loss, loss_summary[1].mean(dim=-1).data.item(), \\\n",
    "                            loss_summary[2].mean(dim=-1).data.item(), \\\n",
    "                            loss_summary[3].mean(dim=-1).data.item(), loss_summary[4]))\n",
    "\n",
    "            iteration += 1\n",
    "            \n",
    "            if annealing_args is not None:\n",
    "                annealing_args['step'] = iteration\n",
    "        \n",
    "        if is_aggressive:\n",
    "            vae.eval()\n",
    "            current_mi = calc_mi(vae, validation_inputs)\n",
    "            vae.train()\n",
    "            print('current_mi:', current_mi)\n",
    "            if current_mi - previous_mi < 0:\n",
    "                is_aggressive = False\n",
    "                print(\"STOP AGGRESSIVE\")\n",
    "\n",
    "            previous_mi = current_mi\n",
    "              \n",
    "        # Validation\n",
    "        vae.eval()\n",
    "        with torch.no_grad():\n",
    "            # NOTE!! if we want to do 100% dropout then we should also add it here.\n",
    "            val_loss, val_kl, val_ppl = test_vae(vae, validation_inputs, validation_targets, val_input_lens, synthetic, annealing_args)\n",
    "            loss, kl, ppl = test_vae(vae, inputs, targets, input_lens, synthetic, annealing_args)\n",
    "            total_epoch_losses.append(loss)\n",
    "            val_total_epoch_losses.append(val_loss)\n",
    "            if verbose:\n",
    "                print ('Epoch [{}/{}], Training Loss: {:.4f},  Training KL: {:.4f}, Training Perplexity: {:5.2f}, Validation Loss: {:.4f}, KL {:.4f}, Val Perplexity: {:5.2f}\\n'\n",
    "                       .format(epoch + 1, epochs, loss, kl, ppl, val_loss, val_kl, val_ppl))\n",
    "            if plot:\n",
    "                plot_mean_space(step, latent_size, vae, tracked_inputs, tracked_targets, lim=plot_lim, iteration=iteration)\n",
    "                \n",
    "            if val_loss > opt_dict[\"best_loss\"]:\n",
    "                opt_dict[\"not_improved\"] += 1\n",
    "                if opt_dict[\"not_improved\"] >= decay_epoch:\n",
    "                    opt_dict[\"best_loss\"] = val_loss\n",
    "                    opt_dict[\"not_improved\"] = 0\n",
    "                    opt_dict[\"lr\"] = opt_dict[\"lr\"] * lr_decay\n",
    "                    #vae.load_state_dict(torch.load(args.save_path))\n",
    "                    print('new lr: %f' % opt_dict[\"lr\"])\n",
    "                    decay_cnt += 1\n",
    "\n",
    "#                     enc_optimizer = torch.optim.SGD(vae.encoder.parameters(), lr=opt_dict[\"lr\"])\n",
    "#                     stoch_enc_optimizer = torch.optim.SGD(vae.stochastic_encoder.parameters(), lr=opt_dict[\"lr\"])\n",
    "#                     stoch_dec_optimizer = torch.optim.SGD(vae.stochastic_decoder.parameters(), lr=opt_dict[\"lr\"])\n",
    "#                     dec_optimizer = torch.optim.SGD(vae.decoder.parameters(), lr=opt_dict[\"lr\"])\n",
    "                    \n",
    "                    enc_optimizer = torch.optim.Adam(vae.encoder.parameters(), lr=opt_dict[\"lr\"])\n",
    "                    stoch_enc_optimizer = torch.optim.Adam(vae.stochastic_encoder.parameters(), lr=opt_dict[\"lr\"])\n",
    "                    stoch_dec_optimizer = torch.optim.Adam(vae.stochastic_decoder.parameters(), lr=opt_dict[\"lr\"])\n",
    "                    dec_optimizer = torch.optim.Adam(vae.decoder.parameters(), lr=opt_dict[\"lr\"])\n",
    "    \n",
    "            else:\n",
    "                opt_dict[\"not_improved\"] = 0\n",
    "                opt_dict[\"best_loss\"] = val_loss\n",
    "            \n",
    "            if decay_cnt == max_decay:\n",
    "                break\n",
    "        vae.train()\n",
    "    \n",
    "    if annealing_args is not None and plot:\n",
    "        plot_kl(kl_terms, kl_weights)\n",
    "    if plot:\n",
    "        plot_losses(total_losses, ce_losses, kl_losses)\n",
    "        plt.plot(total_epoch_losses)\n",
    "        plt.plot(val_total_epoch_losses)\n",
    "        plt.show()\n",
    "        \n",
    "def test_vae(model, inputs, targets, input_lens, synthetic=False, annealing_args=None):\n",
    "    kl_loss = ce_loss = 0\n",
    "    num_words = num_sents = 0\n",
    "    for i in np.random.permutation(len(inputs)):\n",
    "        x = inputs[i]\n",
    "        y = torch.tensor(targets[i].reshape(-1), dtype=torch.long)\n",
    "        x_lens = input_lens[i] if not synthetic else None\n",
    "\n",
    "        batch_size, sents_len, _ = x.shape\n",
    "        if synthetic:\n",
    "            num_words += batch_size * sents_len\n",
    "        else:\n",
    "            num_words = np.sum(x_lens)\n",
    "        \n",
    "        num_sents += batch_size\n",
    "        \n",
    "        mask = None\n",
    "        mean, log_variance, outputs = vae(x, x_lens=x_lens)\n",
    "        if not synthetic:\n",
    "            mask = (y < padding_index)\n",
    "            outputs = outputs[mask]\n",
    "            y = y[mask]\n",
    "\n",
    "        loss_summary = loss_function(outputs, y, mean, log_variance, max_sentence_length, annealing_args=annealing_args, mask=mask)\n",
    "\n",
    "        loss_rc = np.sum(loss_summary[1].data.numpy())\n",
    "        loss_kl = np.sum(loss_summary[3].data.numpy())\n",
    "        \n",
    "        ce_loss += loss_rc.item()\n",
    "        kl_loss += loss_kl.item()\n",
    "\n",
    "    #mutual_info = calc_mi(model, test_data_batch)\n",
    "\n",
    "    loss = (kl_loss + ce_loss) / num_sents\n",
    "    kl = kl_loss / num_sents\n",
    "    ppl = np.exp(loss * num_sents / num_words)\n",
    "\n",
    "    return loss, kl, ppl\n",
    "\n",
    "    \n",
    "def calc_mi(model, test_data_batch):\n",
    "    mi = 0\n",
    "    num_examples = 0\n",
    "    for batch_data in test_data_batch:\n",
    "        batch_size = batch_data.shape[0]\n",
    "        num_examples += batch_size\n",
    "        mutual_info = model.calc_mi(batch_data)\n",
    "        mi += mutual_info * batch_size\n",
    "\n",
    "    return mi / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_active_units(vae, train_inputs, train_lengths=None):\n",
    "    all_mus = None\n",
    "    for i in range(len(train_inputs)):\n",
    "        mus, _ = vae.encode(train_inputs[i], train_lengths[i] if train_lengths is not None else None)\n",
    "        mus = mus.squeeze(0)\n",
    "        if all_mus is None:\n",
    "            all_mus = mus.detach().numpy()\n",
    "        else:\n",
    "            all_mus = np.vstack((mus.detach().numpy(), all_mus))\n",
    "    #print(np.sum(np.var(mus.detach().numpy(), axis=0) > 1e-2))\n",
    "    plt.hist(np.var(mus.detach().numpy(), axis=0), bins=50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pGrpkEVJbZL6"
   },
   "source": [
    "### Load Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-g1xoseTbZL7"
   },
   "outputs": [],
   "source": [
    "test_syn_data = np.loadtxt('synthetic-data/synthetic_test.txt', dtype=int)\n",
    "train_syn_data = np.loadtxt('synthetic-data/synthetic_train.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZfk9HgrbZL-"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# load tracked inputs (for plotting)\n",
    "random_indices = np.random.choice(train_syn_data.shape[0], 500)\n",
    "tracked_inputs = []\n",
    "tracked_targets = []\n",
    "for random_index in random_indices:\n",
    "    tracked_inputs.append(train_syn_data[random_index, :-1])\n",
    "    tracked_targets.append(train_syn_data[random_index, 1:])\n",
    "tracked_inputs = np.expand_dims(np.array(tracked_inputs), axis=-1)\n",
    "tracked_targets = np.expand_dims(np.array(tracked_targets), axis=-1)\n",
    "\n",
    "# load data into batches\n",
    "inputs, targets = get_batches_synthetic(train_syn_data, batch_size)\n",
    "val_inputs, val_targets = get_batches_synthetic(test_syn_data, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6IIuzUnbZMh"
   },
   "source": [
    "### Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Hzwy-xKbZMi",
    "outputId": "a9700e02-3f3d-4483-8b56-25bb821067e3",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 iteration 0 loss 62.174 CE 62.174 KL 0.000 weighted KL: 0.000 weight 1.000\n",
      "epoch 1 iteration 100 loss 46.946 CE 46.946 KL 0.000 weighted KL: 0.000 weight 1.000\n",
      "epoch 1 iteration 200 loss 48.810 CE 48.810 KL 0.000 weighted KL: 0.000 weight 1.000\n",
      "epoch 1 iteration 300 loss 40.934 CE 40.933 KL 0.001 weighted KL: 0.001 weight 1.000\n",
      "epoch 1 iteration 400 loss 35.224 CE 35.221 KL 0.003 weighted KL: 0.003 weight 1.000\n",
      "epoch 1 iteration 500 loss 36.441 CE 36.439 KL 0.001 weighted KL: 0.001 weight 1.000\n",
      "epoch 1 iteration 600 loss 32.946 CE 32.946 KL 0.000 weighted KL: 0.000 weight 1.000\n",
      "epoch 1 iteration 700 loss 33.740 CE 33.739 KL 0.000 weighted KL: 0.000 weight 1.000\n",
      "epoch 1 iteration 800 loss 34.627 CE 34.627 KL 0.000 weighted KL: 0.000 weight 1.000\n",
      "epoch 1 iteration 900 loss 33.956 CE 33.955 KL 0.000 weighted KL: 0.000 weight 1.000\n",
      "Epoch [1/30], Training Loss: 34.5224,  Training KL: 0.0002, Training Perplexity: 46.33, Validation Loss: 38.8493, KL 0.0002, Val Perplexity: 74.93\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 iteration 1000 loss 33.025 CE 33.024 KL 0.000 weighted KL: 0.000 weight 1.000\n",
      "epoch 2 iteration 1100 loss 33.252 CE 33.251 KL 0.001 weighted KL: 0.001 weight 1.000\n",
      "epoch 2 iteration 1200 loss 36.115 CE 36.110 KL 0.005 weighted KL: 0.005 weight 1.000\n",
      "epoch 2 iteration 1300 loss 32.930 CE 32.929 KL 0.001 weighted KL: 0.001 weight 1.000\n",
      "epoch 2 iteration 1400 loss 36.483 CE 36.481 KL 0.001 weighted KL: 0.001 weight 1.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-97fcb3dc2c99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m train(vae, inputs, targets, val_inputs, val_inputs, epochs, vocab_size, hidden_size, latent_size, max_sentence_length, plot=True, learning_rate=learning_rate,\n\u001b[0;32m---> 16\u001b[0;31m       synthetic=True, step=step, tracked_inputs=tracked_inputs, tracked_targets=tracked_targets, plot_lim=1.5, verbose=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-7703d66ede12>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(vae, inputs, targets, validation_inputs, validation_targets, epochs, vocab_size, hidden_size, latent_size, max_sentence_length, num_layers, learning_rate, synthetic, input_lens, val_input_lens, dropout_rate, unk_index, plot, plot_lim, step, tracked_inputs, tracked_targets, annealing_args, is_aggressive, verbose)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mkl_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# without annealing\n",
    "vocab_size = 1000\n",
    "hidden_size = 50\n",
    "embedding_size = 50\n",
    "latent_size = 1\n",
    "num_layers = 1\n",
    "step = 0.25\n",
    "learning_rate = 0.01\n",
    "epochs = 30\n",
    "max_sentence_length = 10\n",
    "\n",
    "embedding_weights = nn.Embedding(vocab_size, embedding_size).weight\n",
    "vae = VAE(hidden_size, num_layers, embedding_weights, latent_size, synthetic=True)\n",
    "\n",
    "train(vae, inputs, targets, val_inputs, val_inputs, epochs, vocab_size, hidden_size, latent_size, max_sentence_length, plot=True, learning_rate=learning_rate,\n",
    "      synthetic=True, step=step, tracked_inputs=tracked_inputs, tracked_targets=tracked_targets, plot_lim=1.5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_active_units(vae, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSToDB3RbZMl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with annealing\n",
    "vocab_size = 1000\n",
    "hidden_size = 50\n",
    "embedding_size = 50\n",
    "latent_size = 1\n",
    "num_layers = 1\n",
    "step = 0.25\n",
    "learning_rate = 1.0\n",
    "epochs = 10\n",
    "max_sentence_length = 10\n",
    "\n",
    "embedding_weights = nn.Embedding(vocab_size, embedding_size).weight\n",
    "vae = VAE(hidden_size, num_layers, embedding_weights, latent_size, synthetic=True)\n",
    "\n",
    "annealing_args = {'type':'logistic', 'step':0, 'k':0.0025, 'first_step':2500}\n",
    "\n",
    "train(vae, inputs, targets, val_inputs, val_targets, epochs, vocab_size, hidden_size, latent_size, max_sentence_length, plot=True, learning_rate=learning_rate,\n",
    "      synthetic=True, step=step, plot_lim=3, annealing_args=annealing_args, tracked_inputs=tracked_inputs, \n",
    "      tracked_targets=tracked_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_active_units(vae, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6038
    },
    "colab_type": "code",
    "id": "RvITCzNRbZMn",
    "outputId": "29295924-4ea6-47a2-b5cb-ecc92f22c8d4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# aggresive training\n",
    "vocab_size = 1000\n",
    "hidden_size = 50\n",
    "embedding_size = 50\n",
    "latent_size = 1\n",
    "num_layers = 1\n",
    "step = 0.25\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "max_sentence_length = 10\n",
    "\n",
    "embedding_weights = nn.Embedding(vocab_size, embedding_size).weight\n",
    "vae = VAE(hidden_size, num_layers, embedding_weights, latent_size, synthetic=True)\n",
    "\n",
    "train(vae, inputs, targets, val_inputs, val_targets, epochs, vocab_size, hidden_size, latent_size, max_sentence_length, plot=True, learning_rate=learning_rate,\n",
    "      synthetic=True, step=step, tracked_inputs=tracked_inputs, tracked_targets=tracked_targets, plot_lim=1.5, is_aggressive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_active_units(vae, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oi_1kQ53bZMq"
   },
   "source": [
    "# TEXT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNvRgoahbZL3"
   },
   "source": [
    "### Load Penn Treebank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WK_Yh_Y9bZL4"
   },
   "outputs": [],
   "source": [
    "max_sentence_length = 50\n",
    "train_data, train_data_padded = load_data(\"data/ptb.train.txt\", max_sentence_length)\n",
    "val_data, val_data_padded = load_data(\"data/ptb.valid.txt\", max_sentence_length)\n",
    "test_data, test_data_padded = load_data(\"data/ptb.test.txt\", max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "qAlIrWZTbZMu",
    "outputId": "abd74738-34f0-4baf-da5d-ffc620d73d36"
   },
   "outputs": [],
   "source": [
    "embedding_size = 500\n",
    "epochs_w2v = 100\n",
    "\n",
    "word2vec_model = Word2Vec(train_data, min_count=1, size=embedding_size, window=5)\n",
    "word2vec_model.train(train_data, epochs=epochs_w2v, total_examples=word2vec_model.corpus_count)\n",
    "\n",
    "word2vec_model = Word2Vec.load(\"word2vec.model\")\n",
    "# print(word2vec_model.wv.most_similar(\"stocks\"))\n",
    "# word2vec_model.wv['credit']\n",
    "\n",
    "vocabulary_size = len(word2vec_model.wv.vocab)\n",
    "# print(\"size of the vocabulary:\", vocabulary_size)\n",
    "# word2vec_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "qAlIrWZTbZMu",
    "outputId": "abd74738-34f0-4baf-da5d-ffc620d73d36"
   },
   "outputs": [],
   "source": [
    "# make the word embeddings into a pythorch tensor\n",
    "embedding_weights = word2vec_model.wv.vectors\n",
    "embedding_weights = np.vstack((embedding_weights, np.zeros((1,embedding_size))))  # add zero vector for <pad>\n",
    "embedding_weights = torch.tensor(embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "use_first_k = 500\n",
    "padding_index = vocabulary_size\n",
    "train_batches, train_targets, train_sentence_lens = get_batches_text(train_data[:use_first_k], train_data_padded[:use_first_k], \n",
    "                                                                batch_size, padding_index, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with annealing\n",
    "vocab_size = 1000\n",
    "hidden_size = 50\n",
    "embedding_size = 50\n",
    "latent_size = 2\n",
    "num_layers = 1\n",
    "step = 0.25\n",
    "learning_rate = 0.01\n",
    "epochs = 1\n",
    "\n",
    "vae = VAE(hidden_size, num_layers, embedding_weights, latent_size, synthetic=False)\n",
    "\n",
    "annealing_args = {'type':'logistic', 'step':0, 'k':0.0025, 'first_step':2500}\n",
    "\n",
    "train(vae, inputs, targets, val_inputs, val_targets, epochs, vocab_size, hidden_size, latent_size, max_sentence_length, plot=False, learning_rate=learning_rate,\n",
    "      synthetic=True, step=step, plot_lim=3, annealing_args=annealing_args, tracked_inputs=tracked_inputs, \n",
    "      tracked_targets=tracked_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference/Generation/Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(vae, z, first_word_index, last_word_index, max_sentence_length):\n",
    "    generator_batch_size = z.shape[0]\n",
    "    hidden_concatenated = vae.stochastic_decoder.forward(z)\n",
    "    hidden = torch.split(hidden_concatenated, vae.hidden_dim, dim=-1)\n",
    "    generated_sequence = greedy(vae, hidden, first_word_index, last_word_index, max_sentence_length, generator_batch_size)\n",
    "    return generated_sequence\n",
    "\n",
    "def greedy(vae, hidden, first_word_index, last_word_index, max_sentence_length, generator_batch_size):\n",
    "    vae_decoder = vae.decoder   \n",
    "    first_word_index = torch.tensor(first_word_index, dtype=torch.long)\n",
    "    predicted = []\n",
    "    curr_words = torch.tensor([first_word_index] * generator_batch_size, dtype=torch.long).unsqueeze(1)\n",
    "    iteration = 0\n",
    "    while iteration != max_sentence_length: #next_word_index != last_word_index and\n",
    "        curr_words_embeddings = vae_decoder.embed(curr_words)\n",
    "        curr_words_embeddings = curr_words_embeddings.view(generator_batch_size, 1, vae_decoder.embedding_size)\n",
    "        \n",
    "        outputs, hidden = vae_decoder.lstm(curr_words_embeddings.float(), (hidden[0].unsqueeze(0), hidden[1].unsqueeze(0)))\n",
    "        outputs = vae_decoder.linear(outputs)\n",
    "        outputs = outputs.squeeze(1)\n",
    "        hidden = (hidden[0].squeeze(0), hidden[1].squeeze(0))\n",
    "        softmax_outputs = F.softmax(outputs, dim=1).detach().numpy()\n",
    "    \n",
    "        next_words_indices = []\n",
    "        for t in range(generator_batch_size):\n",
    "            \n",
    "            # IS THE NEXT LINE OK? DO INDICES MATCH PROBABILITES?            \n",
    "            \n",
    "            next_words_indices.append(np.random.choice(np.arange(softmax_outputs.shape[1]), size=1, p=softmax_outputs[t])[0])        \n",
    "        curr_words = torch.tensor(next_words_indices, dtype=torch.long).unsqueeze(1)\n",
    "                \n",
    "        predicted.append(next_words_indices)\n",
    "\n",
    "        iteration += 1\n",
    "        \n",
    "#     if predicted[-1] != last_word_index:\n",
    "#         predicted.append(last_word_index)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z1 = torch.randn([latent_size]).numpy()\n",
    "z2 = torch.randn([latent_size]).numpy()\n",
    "number_of_sentences_to_decode = 2\n",
    "max_sentence_length = 10\n",
    "interpolation_points = generate_interpolation_sequence(z1, z2, number_of_sentences_to_decode=number_of_sentences_to_decode)\n",
    "\n",
    "sentences = generate(vae, torch.tensor(interpolation_points, dtype=torch.float), word2vec_model.wv.vocab['<sos>'].index, word2vec_model.wv.vocab['<eos>'].index, max_sentence_length)\n",
    "words_sentences = []\n",
    "sentences = np.array(sentences).T\n",
    "for curr_sentence in sentences:\n",
    "    words_curr_sentence = []\n",
    "    for j in curr_sentence:\n",
    "        words_curr_sentence.append(word2vec_model.wv.index2word[j])\n",
    "    words_sentences.append(words_curr_sentence)\n",
    "for s in words_sentences:\n",
    "    for word in s:\n",
    "        print(word, end = ' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VFd2wVP_bZMq"
   },
   "source": [
    "### Create Word2Vec word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P7x5P4wJbZMw"
   },
   "source": [
    "### Define RNNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sezQbDZvbZMw"
   },
   "outputs": [],
   "source": [
    "class RNNLM(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_size, hidden_size, num_layers, embedding_weights):\n",
    "        super(RNNLM, self).__init__()\n",
    "        self.embed = nn.Embedding.from_pretrained(embedding_weights)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocabulary_size)\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "    def forward(self, x, hidden, x_lens, train=True):\n",
    "        batch_size, max_len, _ = x.shape\n",
    "        embedding_dim = self.embedding_size\n",
    "\n",
    "        x = self.embed(torch.tensor(x, dtype=torch.long)).view(batch_size, max_len, embedding_dim)\n",
    "        if train:\n",
    "            x_lens = torch.tensor(x_lens, dtype=torch.long)\n",
    "            x = pack_padded_sequence(x, x_lens, batch_first=True)\n",
    "\n",
    "        out, hidden = self.lstm(x.float(), hidden) \n",
    "        \n",
    "        if train:\n",
    "            out, output_lens = pad_packed_sequence(out, batch_first=True, total_length=max_sentence_length-1)\n",
    "\n",
    "        out = out.reshape(out.size(0)*out.size(1), out.size(2))\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3b909vPhbZMy"
   },
   "source": [
    "### Train and predict with RNNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1689
    },
    "colab_type": "code",
    "id": "DNAqnNW2bZMz",
    "outputId": "e8b5de4f-81c2-4f4c-9caa-caf4be8b18d3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size = 100\n",
    "output_size = 100\n",
    "hidden_size = 50\n",
    "\n",
    "batch_size = 20\n",
    "use_first_k = 500\n",
    "padding_index = vocabulary_size\n",
    "train_batches, train_targets, train_sentence_lens = get_batches_text(train_data[:use_first_k], train_data_padded[:use_first_k], \n",
    "                                                                batch_size, padding_index, word2vec_model)\n",
    "\n",
    "# make the word embeddings into a pythorch tensor\n",
    "embedding_weights = word2vec_model.wv.vectors\n",
    "embedding_weights = np.vstack((embedding_weights, np.zeros((1,embedding_size))))  # add zero vector for <pad>\n",
    "embedding_weights = torch.tensor(embedding_weights)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_layers = 1\n",
    "epochs = 100\n",
    "\n",
    "model = RNNLM(vocabulary_size, embedding_size, hidden_size, num_layers, embedding_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hidden = (torch.zeros(num_layers, batch_size, hidden_size), torch.zeros(num_layers, batch_size, hidden_size))\n",
    "    for i in range(len(train_batches)):\n",
    "        x = train_batches[i]\n",
    "        x_lens = train_sentence_lens[i]\n",
    "        y = torch.tensor(train_targets[i].reshape(-1), dtype=torch.long)   \n",
    "        h, c = hidden\n",
    "        h = h.detach()\n",
    "        c = c.detach()\n",
    "        hidden = (h, c)\n",
    "    \n",
    "        outputs, hidden = model(x, hidden, x_lens)\n",
    "        \n",
    "        mask = (y < padding_index)\n",
    "        loss = nn.CrossEntropyLoss()(outputs[mask], y[mask])\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'\n",
    "               .format(epoch + 1, epochs, loss.item(), np.exp(loss.item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "oaQPc6BXbZM1",
    "outputId": "e2442573-b581-4f04-96bf-5621aaa340ca"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "test_sentences = [\"in terms\"]\n",
    "sentence, _ = tokenize_sentence(test_sentences[0], max_sentence_length)\n",
    "sentence = sentence[:-1]\n",
    "word_indexes = np.array([word2vec_model.wv.vocab[word].index for word in sentence]).reshape(1, len(sentence), 1)\n",
    "\n",
    "hidden = (torch.zeros(1, 1, hidden_size), torch.zeros(1, 1, hidden_size))\n",
    "h, c = hidden\n",
    "h = h.detach()\n",
    "c = c.detach()\n",
    "hidden = (h, c)\n",
    "\n",
    "outputs, hidden = model(word_indexes, hidden, x_lens, train=False)\n",
    "softmax_outputs = F.softmax(outputs, dim=1).detach().numpy()\n",
    "last_word = softmax_outputs[-1,:]\n",
    "\n",
    "predicted_next_word_idx = np.random.choice(range(len(last_word)), p=last_word)\n",
    "print(\"Argmax: \", word2vec_model.wv.index2word[np.argmax(last_word)])\n",
    "print(\"Next word: \", word2vec_model.wv.index2word[predicted_next_word_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BliAoNIsiUr"
   },
   "source": [
    "### Yelp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_len = 50\n",
    "yelp_train_data_original, yelp_train_data_padded = load_data(\"yelp_data/yelp.train.txt\", max_sentence_len, with_labels=True)\n",
    "yelp_test_data_original, yelp_test_data_padded = load_data(\"yelp_data/yelp.test.txt\", max_sentence_len, with_labels=True)\n",
    "yelp_val_dat_original, yelp_val_data_padded = load_data(\"yelp_data/yelp.valid.txt\", max_sentence_len, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 512\n",
    "epochs_w2v = 100\n",
    "word2vec_model_name = \"word2vec_yelp.model\"\n",
    "\n",
    "if os.path.isfile(word2vec_model_name):\n",
    "    print('Loading word2vec model:', word2vec_model_name)\n",
    "    word2vec_yelp = Word2Vec.load(word2vec_model_name)\n",
    "else:\n",
    "    print('Training word2vec model')\n",
    "    word2vec_yelp = Word2Vec(yelp_train_data_original, min_count=1, size=embedding_size, window=5)\n",
    "    word2vec_yelp.train(yelp_train_data_original, epochs=epochs_w2v, total_examples=word2vec_yelp.corpus_count)\n",
    "    word2vec_yelp.save(word2vec_model_name)\n",
    "    print('Saved word2vec model:', word2vec_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the word embeddings into a pythorch tensor\n",
    "embedding_weights = word2vec_yelp.wv.vectors\n",
    "embedding_weights = np.vstack((embedding_weights, np.zeros((1,embedding_size))))  # add zero vector for <pad>\n",
    "embedding_weights = torch.tensor(embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word2vec_yelp.wv.most_similar(\"coffee\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "vocabulary_size = len(word2vec_yelp.wv.vocab)\n",
    "padding_index = vocabulary_size\n",
    "\n",
    "yelp_train_inputs, yelp_train_targets, yelp_train_lengths = \\\n",
    "                get_batches_text(yelp_train_data_original, yelp_train_data_padded, batch_size, padding_index, word2vec_yelp, '_unk')\n",
    "\n",
    "yelp_test_inputs, yelp_test_targets, yelp_test_lengths = \\\n",
    "                get_batches_text(yelp_test_data_original, yelp_test_data_padded, batch_size, padding_index, word2vec_yelp, '_unk')\n",
    "\n",
    "yelp_val_inputs, yelp_val_targets, yelp_val_lengths = \\\n",
    "                get_batches_text(yelp_val_dat_original, yelp_val_data_padded, batch_size, padding_index, word2vec_yelp, '_unk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1024\n",
    "latent_size = 1\n",
    "num_layers = 1\n",
    "step = 0.25\n",
    "learning_rate = 0.01\n",
    "epochs = 5\n",
    "\n",
    "vae = VAE(hidden_size, num_layers, embedding_weights, latent_size, synthetic=True)\n",
    "\n",
    "train(vae, yelp_train_inputs[:], yelp_train_targets[:], yelp_val_inputs, yelp_val_targets, epochs, vocabulary_size, \n",
    "      hidden_size, latent_size, max_sentence_length, yelp_train_lengths[:], plot=False, learning_rate=learning_rate,\n",
    "      synthetic=False, step=step, tracked_inputs=None, tracked_targets=None, plot_lim=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENCODER-DECODER BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    # just a basic encoder-decoder with no VAE layers in the middle\n",
    "    def __init__(self, hidden_dim, num_layers, embedding_weights, synthetic=False):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_first = True\n",
    "        \n",
    "        self.encoder = Encoder(self.hidden_dim, num_layers, embedding_weights, synthetic)\n",
    "        self.decoder = Decoder(self.hidden_dim, num_layers, embedding_weights, synthetic)\n",
    "\n",
    "        if synthetic:          \n",
    "            for param in self.parameters():\n",
    "                nn.init.uniform_(param, -0.01, 0.01)\n",
    "            nn.init.uniform_(self.encoder.embed.weight, -0.1, 0.1)\n",
    "            nn.init.uniform_(self.decoder.embed.weight, -0.1, 0.1)\n",
    "        \n",
    "    def encode(self, x, x_lens=None):\n",
    "        batch_size, max_len, _ = x.shape\n",
    "        hidden = self.encoder.init_hidden(batch_size)\n",
    "        _, hidden = self.encoder.forward(x, hidden, x_lens)\n",
    "        return hidden\n",
    "        \n",
    "    def decode(self, hidden, x, x_lens=None, train=True): \n",
    "        outputs, _ = self.decoder.forward(x, hidden, x_lens, train)\n",
    "        return outputs\n",
    "    \n",
    "    def forward(self, x, x_lens=None):\n",
    "        # the last hidden state of the encoder is the first hidden state of the decoder\n",
    "        hidden = self.encode(x, x_lens)\n",
    "#         hidden_concatenated = self.stochastic_decoder.forward(z)\n",
    "#         hidden = torch.split(hidden_concatenated, self.hidden_dim, dim=2)\n",
    "        outputs = self.decode(hidden, x, x_lens)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_loss_function(outputs, labels, seq_length, batch_size, mask=None):\n",
    "    if mask is not None:\n",
    "        BCE = torch.zeros(batch_size * (seq_length - 1))\n",
    "        BCE[mask] = nn.CrossEntropyLoss(reduction='none')(outputs, labels)\n",
    "    else:\n",
    "        BCE = nn.CrossEntropyLoss(reduction='none')(outputs, labels)\n",
    "    BCE = BCE.view(batch_size, -1).sum(-1)\n",
    "    return BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline(model, inputs, targets, input_lens, synthetic=False):\n",
    "    total_loss = 0\n",
    "    num_words = num_sents = 0\n",
    "    for i in np.random.permutation(len(inputs)):\n",
    "        x = inputs[i]\n",
    "        y = torch.tensor(targets[i].reshape(-1), dtype=torch.long)\n",
    "        x_lens = input_lens[i] if not synthetic else None\n",
    "\n",
    "        batch_size, sents_len, _ = x.shape\n",
    "        if synthetic:\n",
    "            num_words += batch_size * sents_len\n",
    "        else:\n",
    "            num_words = np.sum(x_lens)\n",
    "        num_sents += batch_size\n",
    "        \n",
    "        mask = None\n",
    "        outputs = model(x, x_lens=x_lens)\n",
    "        if not synthetic:\n",
    "            mask = (y < padding_index)\n",
    "            outputs = outputs[mask]\n",
    "            y = y[mask]\n",
    "        curr_loss = baseline_loss_function(outputs, y, max_sentence_length, batch_size, mask=mask)\n",
    "        curr_loss = np.sum(curr_loss.data.numpy())\n",
    "        total_loss += curr_loss.item()\n",
    "    \n",
    "    total_loss /= num_sents\n",
    "    ppl = np.exp(total_loss * num_sents / num_words)\n",
    "    return total_loss, ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline(model, inputs, targets, val_inputs, val_targets, epochs, vocab_size, hidden_size, \n",
    "                   max_sentence_length, input_lens=None, val_input_lens=None, synthetic=False, \n",
    "                   num_layers=1, learning_rate=0.001, verbose_level=1, plot=False):\n",
    "\n",
    "    opt_dict = {\"not_improved\": 0, \"lr\": learning_rate, \"best_loss\": 1e4}\n",
    "    decay_epoch = 2\n",
    "    lr_decay = 0.5\n",
    "    max_decay = 5\n",
    "    decay_cnt = 0\n",
    "    \n",
    "    enc_optimizer = torch.optim.SGD(model.encoder.parameters(), lr=learning_rate)\n",
    "    dec_optimizer = torch.optim.SGD(model.decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    iteration = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "            \n",
    "    for epoch in range(epochs):        \n",
    "        for i in np.random.permutation(len(inputs)):\n",
    "            x = inputs[i]\n",
    "            y = torch.tensor(targets[i].reshape(-1), dtype=torch.long)\n",
    "            x_lens = input_lens[i] if not synthetic else None \n",
    "          \n",
    "            batch_size, _, _ = x.shape\n",
    "            mask = None\n",
    "            # do the forward pass\n",
    "            outputs = model(x, x_lens=x_lens)\n",
    "\n",
    "            if not synthetic:\n",
    "                mask = (y < padding_index)\n",
    "                outputs = outputs[mask]\n",
    "                y = y[mask]\n",
    "            \n",
    "            enc_optimizer.zero_grad()\n",
    "            dec_optimizer.zero_grad()\n",
    "            \n",
    "            # compute the cross entropy loss\n",
    "            loss = baseline_loss_function(outputs, y, max_sentence_length, batch_size, mask=mask)                \n",
    "            loss = loss.mean(dim=-1) # take the mean (same as divide by batch size?)\n",
    "            \n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), 5.0)\n",
    "            enc_optimizer.step()\n",
    "            dec_optimizer.step()\n",
    "            \n",
    "            if (iteration % 100 == 0) and (verbose_level == 2):\n",
    "                print('epoch {}\\titeration {}\\ttraining loss {:.3f}'.format(epoch+1, iteration, loss))\n",
    "\n",
    "            iteration += 1\n",
    "              \n",
    "        # evaluate on the validation data\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_loss, train_ppl = test_baseline(model, inputs, targets, input_lens, synthetic)\n",
    "            val_loss, val_ppl = test_baseline(model, val_inputs, val_targets, val_input_lens, synthetic)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            if verbose_level > 0:\n",
    "                print ('Epoch [{}/{}], Training Loss: {:.4f} Perplexity: {:.4f}, Validation Loss: {:.4f} Perplexity {:.4f}'\n",
    "                       .format(epoch+1, epochs, train_loss, train_ppl, val_loss, val_ppl))\n",
    "\n",
    "            # are we still decaying with the same logic?\n",
    "            if val_loss > opt_dict[\"best_loss\"]:\n",
    "                opt_dict[\"not_improved\"] += 1\n",
    "                if opt_dict[\"not_improved\"] >= decay_epoch:\n",
    "                    opt_dict[\"best_loss\"] = val_loss\n",
    "                    opt_dict[\"not_improved\"] = 0\n",
    "                    opt_dict[\"lr\"] = opt_dict[\"lr\"] * lr_decay\n",
    "                    #vae.load_state_dict(torch.load(args.save_path))\n",
    "                    print('new lr: %f' % opt_dict[\"lr\"])\n",
    "                    decay_cnt += 1\n",
    "\n",
    "                    enc_optimizer = torch.optim.SGD(model.encoder.parameters(), lr=opt_dict[\"lr\"])\n",
    "                    dec_optimizer = torch.optim.SGD(model.decoder.parameters(), lr=opt_dict[\"lr\"])\n",
    "            else:\n",
    "                opt_dict[\"not_improved\"] = 0\n",
    "                opt_dict[\"best_loss\"] = val_loss\n",
    "            \n",
    "            if decay_cnt == max_decay:\n",
    "                break\n",
    "        model.train()\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(train_losses)\n",
    "        plt.plot(val_losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without annealing\n",
    "vocab_size = 1000\n",
    "hidden_size = 50\n",
    "embedding_size = 50\n",
    "num_layers = 1\n",
    "learning_rate = 1.0\n",
    "epochs = 20\n",
    "max_sentence_length = 10\n",
    "\n",
    "embedding_weights = nn.Embedding(vocab_size, embedding_size).weight\n",
    "baseline_model = Baseline(hidden_size, num_layers, embedding_weights, synthetic=True)\n",
    "\n",
    "# verbose level 0 - print nothing\n",
    "# verbose level 1 - print only at the end of each epoch\n",
    "# verbose level 2 - print everything\n",
    "verbose_level = 1\n",
    "\n",
    "train_baseline(baseline_model, inputs, targets, val_inputs, val_targets, epochs, vocab_size, hidden_size, max_sentence_length, \n",
    "               learning_rate=learning_rate, synthetic=True, verbose_level=verbose_level, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_length = 50\n",
    "train_data, train_data_padded = load_data(\"data/ptb.train.txt\", max_sentence_length)\n",
    "val_data, val_data_padded = load_data(\"data/ptb.valid.txt\", max_sentence_length)\n",
    "test_data, test_data_padded = load_data(\"data/ptb.test.txt\", max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 512\n",
    "epochs_w2v = 100\n",
    "\n",
    "word2vec_model = Word2Vec(train_data, min_count=1, size=embedding_size, window=5)\n",
    "word2vec_model.train(train_data, epochs=epochs_w2v, total_examples=word2vec_model.corpus_count)\n",
    "\n",
    "# word2vec_model = Word2Vec.load(\"word2vec.model\")\n",
    "# print(word2vec_model.wv.most_similar(\"stocks\"))\n",
    "# word2vec_model.wv['credit']\n",
    "\n",
    "vocabulary_size = len(word2vec_model.wv.vocab)\n",
    "# print(\"size of the vocabulary:\", vocabulary_size)\n",
    "# word2vec_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the word embeddings into a pythorch tensor\n",
    "embedding_weights = word2vec_model.wv.vectors\n",
    "embedding_weights = np.vstack((embedding_weights, np.zeros((1,embedding_size))))  # add zero vector for <pad>\n",
    "embedding_weights = torch.tensor(embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# use_first_k = 500\n",
    "padding_index = vocabulary_size\n",
    "train_batches, train_targets, train_sentence_lens = get_batches_text(train_data, train_data_padded, batch_size, padding_index, word2vec_model)\n",
    "val_batches, val_targets, val_sentence_lens = get_batches_text(val_data, val_data_padded, batch_size, padding_index, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1024\n",
    "latent_size = 13\n",
    "num_layers = 1\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "# dropout rate 80%\n",
    "unk_index = word2vec_model.wv.vocab[\"<unk>\"].index\n",
    "dropout_prob = 0.8\n",
    "\n",
    "vae = VAE(hidden_size, num_layers, embedding_weights, latent_size, synthetic=False)\n",
    "\n",
    "train(vae, train_batches, train_targets, val_batches, val_targets, epochs, vocab_size, hidden_size, latent_size, \n",
    "      max_sentence_length, plot=False, verbose=True, learning_rate=learning_rate, synthetic=False,\n",
    "      input_lens=train_sentence_lens, val_input_lens=val_sentence_lens, unk_index=unk_index, dropout_rate=dropout_prob)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "refactored-workspace-text.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
