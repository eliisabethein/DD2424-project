{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Mihaela\n",
      "[nltk_data]     Stoycheva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions.normal as normal\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, max_sentence_len):\n",
    "    # the tokenizer splits <unk> so we use MWETokenizer to re-merge it\n",
    "    data_original = []\n",
    "    data_padded = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            sentence, padded_sentence = tokenize_sentence(line, max_sentence_len)\n",
    "            data_original.append(sentence)\n",
    "            data_padded.append(padded_sentence)\n",
    "    \n",
    "    return data_original, data_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(string, max_sentence_len):\n",
    "    merger = MWETokenizer([('<', 'unk', '>')], separator = '') \n",
    "    sentence = word_tokenize(string.strip())       # tokenize sentence\n",
    "    sentence = merger.tokenize(sentence)         # merge <unk>\n",
    "    sentence = sentence[:max_sentence_len - 2]   # cut sentence at max_sentence_length\n",
    "    sentence = ['<sos>'] + sentence + ['<eos>']  # add start and end-of-sentence tags\n",
    "\n",
    "    # pad the rest of the sentence\n",
    "    padded_sentence = sentence.copy()\n",
    "    padded_sentence.extend(['<pad>']*(max_sentence_len - len(sentence))) \n",
    "    \n",
    "    return sentence, padded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches_text(data, data_padded, batch_size, pad_index, word2vec_model):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    lengths = []\n",
    "    for i in range(len(data) // batch_size):\n",
    "        # take batch_size sentences from the data each time\n",
    "        batch_sentences = data[i*batch_size:(i+1)*batch_size]\n",
    "        batch_sentence_lens = [len(x) for x in batch_sentences]\n",
    "        \n",
    "        # sentences in a batch have to be sorted in decreasing order of length (for pack_padded_sentence)\n",
    "        sorted_pairs = sorted(zip(batch_sentence_lens,batch_sentences), reverse=True)\n",
    "        batch_sentences = [sentence for length, sentence in sorted_pairs]\n",
    "        batch_sentence_lens = [length-1 for length, sentence in sorted_pairs]\n",
    "        \n",
    "        # each input and target is a (batch_size x max_sentence_len-1 x 1) matrix\n",
    "        # initially filled with the index for padditng tag <pad>\n",
    "        input_batch = np.ones((batch_size, len(data_padded[0])-1, 1)) * pad_index\n",
    "        target_batch = np.ones((batch_size, len(data_padded[0])-1, 1)) * pad_index\n",
    "        \n",
    "        # for each sentence in the batch, fill the corresponding row in current_batch\n",
    "        # with the indexed of the words in the sentence (except for <pad>)\n",
    "        for j, sentence in enumerate(batch_sentences):\n",
    "            word_indexes = np.array([word2vec_model.wv.vocab[word].index for word in sentence])\n",
    "            input_batch[j,0:len(sentence)-1,0] = word_indexes[:-1]\n",
    "            target_batch[j,0:len(sentence)-1,0] = word_indexes[1:]\n",
    "        \n",
    "        # make the matrices into torch tensors and append\n",
    "        inputs.append(input_batch)\n",
    "        targets.append(target_batch)\n",
    "        lengths.append(batch_sentence_lens)\n",
    "    return inputs, targets, lengths\n",
    "\n",
    "def get_batches_synthetic(data, batch_size):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(data) // batch_size):\n",
    "        batch_sentences = data[i * batch_size:(i+1) * batch_size]\n",
    "\n",
    "        input_batch = np.ones((batch_size, data.shape[1] - 1, 1)) \n",
    "        target_batch = np.ones((batch_size, data.shape[1] - 1, 1)) \n",
    "        for j, sentence in enumerate(batch_sentences):\n",
    "                input_batch[j,0:len(sentence)-1,0] = sentence[:-1]\n",
    "                target_batch[j,0:len(sentence)-1,0] = sentence[1:]\n",
    "        inputs.append(input_batch)\n",
    "        targets.append(target_batch)\n",
    "    \n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Penn Treebank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_sentence_length = 50\n",
    "# train_data, train_data_padded = load_data(\"data/ptb.train.txt\", max_sentence_length)\n",
    "# val_data, val_data_padded = load_data(\"data/ptb.valid.txt\", max_sentence_length)\n",
    "# test_data, test_data_padded = load_data(\"data/ptb.test.txt\", max_sentence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_syn_data = np.loadtxt('./synthetic-data/synthetic_test.txt', dtype=int)\n",
    "train_syn_data = np.loadtxt('./synthetic-data/synthetic_train.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# load tracked inputs (for plotting)\n",
    "random_indices = np.random.choice(train_syn_data.shape[0], 500)\n",
    "tracked_inputs = []\n",
    "tracked_targets = []\n",
    "for random_index in random_indices:\n",
    "    tracked_inputs.append(train_syn_data[random_index, :-1])\n",
    "    tracked_targets.append(train_syn_data[random_index, 1:])\n",
    "tracked_inputs = np.expand_dims(np.array(tracked_inputs), axis=-1)\n",
    "tracked_targets = np.expand_dims(np.array(tracked_targets), axis=-1)\n",
    "\n",
    "# load data into batches\n",
    "inputs, targets = get_batches_synthetic(train_syn_data, batch_size)\n",
    "val_inputs, val_targets = get_batches_synthetic(test_syn_data, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, embedding_weights, synthetic=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        # parameters\n",
    "        self.embedding_size = embedding_weights.shape[1]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = True\n",
    "        \n",
    "        #layers\n",
    "        self.embed = nn.Embedding.from_pretrained(embedding_weights)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, batch_first=self.batch_first)\n",
    "        \n",
    "    def forward(self, x, hidden, x_lens=None, train=True):\n",
    "        batch_size, max_len, _ = x.shape\n",
    "        \n",
    "        x = torch.tensor(x, dtype=torch.long)  # make the input into a torch tensor\n",
    "        x = self.embed(x).view(batch_size, max_len, self.embedding_size)\n",
    "\n",
    "        if x_lens is not None and train:\n",
    "            x_lens = torch.tensor(x_lens, dtype=torch.long)\n",
    "            x = pack_padded_sequence(x, x_lens, batch_first=self.batch_first)\n",
    "            \n",
    "        output, hidden = self.lstm(x.float(), hidden) \n",
    "\n",
    "        if x_lens is not None and train:\n",
    "            output, output_lens = pad_packed_sequence(output, batch_first=self.batch_first, \n",
    "                                                      total_length=max_sentence_length-1)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        c = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,hidden_size, num_layers, embedding_weights, synthetic=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        # parameters\n",
    "        self.vocabulary_size = embedding_weights.shape[0]\n",
    "        self.embedding_size = embedding_weights.shape[1]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = True\n",
    "        \n",
    "        # layers\n",
    "        self.embed = nn.Embedding.from_pretrained(embedding_weights)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, batch_first=self.batch_first)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.vocabulary_size)\n",
    "\n",
    "    def forward(self, x, hidden, x_lens=None, train=True):\n",
    "        batch_size, max_len, _ = x.shape\n",
    "        \n",
    "        x = torch.tensor(x, dtype=torch.long)  # make the input into a torch tensor\n",
    "        x = self.embed(x).view(batch_size, max_len, self.embedding_size)\n",
    "        \n",
    "        if x_lens is not None and train:\n",
    "            x_lens = torch.tensor(x_lens, dtype=torch.long)\n",
    "            x = pack_padded_sequence(x, x_lens, batch_first=self.batch_first)\n",
    "\n",
    "        output, hidden = self.lstm(x.float(), hidden) \n",
    "        \n",
    "        if x_lens is not None and train:\n",
    "            output, output_lens = pad_packed_sequence(output, batch_first=self.batch_first, \n",
    "                                                      total_length=max_sentence_length-1)\n",
    "        \n",
    "        output = output.reshape(output.size(0)*output.size(1), output.size(2))\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Stochastic(nn.Module):\n",
    "#     def __init__(self, hidden_dim, num_layers, latent_dim, synthetic=False):\n",
    "#         super(Stochastic, self).__init__()\n",
    "#         self.latent_dim = latent_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.batch_first = True\n",
    "        \n",
    "#         self.hidden_to_mean = nn.Linear(2 * self.hidden_dim * num_layers, self.latent_dim, self.batch_first)\n",
    "#         self.hidden_to_logvar = nn.Linear(2 * self.hidden_dim * num_layers, self.latent_dim, self.batch_first)\n",
    "#         self.latent_to_hidden = nn.Linear(latent_dim, 2 * self.hidden_dim * num_layers, self.batch_first)\n",
    "        \n",
    "# #         if synthetic:          \n",
    "# #             for param in self.parameters():\n",
    "# #                 nn.init.uniform_(param, -0.01, 0.01)\n",
    "\n",
    "#     def reparametrize(self, mean, log_variance):\n",
    "#         eps = torch.randn_like(mean)\n",
    "#         return mean + eps * torch.exp(0.5 * log_variance)\n",
    "        \n",
    "#     def forward(self, hidden_concatenated):\n",
    "#         mean = self.hidden_to_mean(hidden_concatenated)\n",
    "#         log_variance = self.hidden_to_logvar(hidden_concatenated)\n",
    "#         z = self.reparametrize(mean, log_variance)\n",
    "#         hidden_concatenated = self.latent_to_hidden(z)\n",
    "#         return hidden_concatenated, mean, log_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, latent_dim, synthetic=False):\n",
    "        super(StochasticEncoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_first = True\n",
    "        \n",
    "        self.hidden_to_mean = nn.Linear(2 * self.hidden_dim * num_layers, self.latent_dim, self.batch_first)\n",
    "        self.hidden_to_logvar = nn.Linear(2 * self.hidden_dim * num_layers, self.latent_dim, self.batch_first)\n",
    "\n",
    "    def reparametrize(self, mean, log_variance):\n",
    "        eps = torch.randn_like(mean)\n",
    "        return mean + eps * torch.exp(0.5 * log_variance)\n",
    "        \n",
    "    def forward(self, hidden_concatenated):\n",
    "        mean = self.hidden_to_mean(hidden_concatenated)\n",
    "        log_variance = self.hidden_to_logvar(hidden_concatenated)\n",
    "        z = self.reparametrize(mean, log_variance)\n",
    "        return z, mean, log_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, latent_dim, synthetic=False):\n",
    "        super(StochasticDecoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_first = True\n",
    "        \n",
    "        self.latent_to_hidden = nn.Linear(latent_dim, 2 * self.hidden_dim * num_layers, self.batch_first)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        hidden_concatenated = self.latent_to_hidden(z)\n",
    "        return hidden_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # new VAE\n",
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, hidden_dim, num_layers, embedding_weights, latent_dim, synthetic=False):\n",
    "#         super(VAE, self).__init__()\n",
    "#         self.latent_dim = latent_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.batch_first = True\n",
    "        \n",
    "#         self.encoder = Encoder(self.hidden_dim, num_layers, embedding_weights, synthetic)\n",
    "#         self.stochastic = Stochastic(self.hidden_dim, num_layers, self.latent_dim, synthetic)\n",
    "#         self.decoder = Decoder(self.hidden_dim, num_layers, embedding_weights, synthetic)\n",
    "        \n",
    "#         # THIS PART IS IMPORTANT -- I think it re-initialises all of the weights in the network with\n",
    "#         ## this distribution, even the embedding weights, which we initialised to (-0.1,0.1) before;\n",
    "#         ## with this distribution it (kind of) works both without annealing and with annealing \n",
    "#         ## (why??? who knows)\n",
    "#         if synthetic:          \n",
    "#             for param in self.parameters():\n",
    "#                 nn.init.uniform_(param, -0.01, 0.01)\n",
    "        \n",
    "#     def encode(self, x, x_lens=None):\n",
    "#         batch_size, max_len, _ = x.shape\n",
    "#         hidden = self.encoder.init_hidden(batch_size)\n",
    "#         _, hidden = self.encoder.forward(x, hidden, x_lens)\n",
    "#         return hidden\n",
    "    \n",
    "#     def latent_to_hidden(self, x):\n",
    "#         return self.stochastic.latent_to_hidden(x)\n",
    "        \n",
    "#     def decode(self, hidden, x, x_lens=None, train=True):\n",
    "#         outputs, _ = self.decoder.forward(x, hidden, x_lens, train)\n",
    "#         return outputs\n",
    "    \n",
    "#     def forward(self, x, x_lens=None):\n",
    "#         hidden = self.encode(x, x_lens)\n",
    "#         hidden_concatenated = torch.cat((hidden[0], hidden[1]), 2)\n",
    "#         hidden_concatenated, mean, log_variance = self.stochastic(hidden_concatenated)\n",
    "#         hidden = torch.split(hidden_concatenated, self.hidden_dim, dim=2)\n",
    "#         outputs = self.decode(hidden, x, x_lens)\n",
    "#         return mean, log_variance, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new VAE\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, embedding_weights, latent_dim, synthetic=False):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_first = True\n",
    "        \n",
    "        self.encoder = Encoder(self.hidden_dim, num_layers, embedding_weights, synthetic)\n",
    "        self.stochastic_encoder = StochasticEncoder(self.hidden_dim, num_layers, self.latent_dim, synthetic)\n",
    "        self.stochastic_decoder = StochasticDecoder(self.hidden_dim, num_layers, self.latent_dim, synthetic)\n",
    "        self.decoder = Decoder(self.hidden_dim, num_layers, embedding_weights, synthetic)\n",
    "        \n",
    "        # THIS PART IS IMPORTANT -- I think it re-initialises all of the weights in the network with\n",
    "        ## this distribution, even the embedding weights, which we initialised to (-0.1,0.1) before;\n",
    "        ## with this distribution it (kind of) works both without annealing and with annealing \n",
    "        ## (why??? who knows)\n",
    "        if synthetic:          \n",
    "            for param in self.parameters():\n",
    "                nn.init.uniform_(param, -0.01, 0.01)\n",
    "            nn.init.uniform_(self.encoder.embed.weight, -0.1, 0.1)\n",
    "            nn.init.uniform_(self.decoder.embed.weight, -0.1, 0.1)\n",
    "        \n",
    "    def encode(self, x, x_lens=None):\n",
    "        batch_size, max_len, _ = x.shape\n",
    "        hidden = self.encoder.init_hidden(batch_size)\n",
    "        _, hidden = self.encoder.forward(x, hidden, x_lens)\n",
    "        return hidden\n",
    "    \n",
    "    def latent_to_hidden(self, z):\n",
    "        return self.stochastic_decoder.latent_to_hidden(z)\n",
    "        \n",
    "    def decode(self, hidden, x, x_lens=None, train=True):\n",
    "        outputs, _ = self.decoder.forward(x, hidden, x_lens, train)\n",
    "        return outputs       \n",
    "    \n",
    "    def forward(self, x, x_lens=None):\n",
    "        hidden = self.encode(x, x_lens)\n",
    "        hidden_concatenated = torch.cat((hidden[0], hidden[1]), 2)\n",
    "        z, mean, log_variance = self.stochastic_encoder.forward(hidden_concatenated)\n",
    "        hidden_concatenated = self.stochastic_decoder.forward(z)\n",
    "        hidden = torch.split(hidden_concatenated, self.hidden_dim, dim=2)\n",
    "        outputs = self.decode(hidden, x, x_lens)\n",
    "        return mean, log_variance, outputs\n",
    "    \n",
    "    def calc_mi(self, x):\n",
    "        \"\"\"Approximate the mutual information between x and z\n",
    "        I(x, z) = E_xE_{q(z|x)}log(q(z|x)) - E_xE_{q(z|x)}log(q(z))\n",
    "        Returns: Float\n",
    "        \"\"\"\n",
    "        mean, log_variance, _ = self.forward(x)\n",
    "        _, batch_size, _ = mean.size()\n",
    "\n",
    "        # E_{q(z|x)}log(q(z|x)) = -0.5*nz*log(2*\\pi) - 0.5*(1+logvar).sum(-1)\n",
    "        neg_entropy = (-0.5 * self.latent_dim * np.log(2 * np.pi)- 0.5 * (1 + log_variance).sum(-1)).mean()\n",
    "\n",
    "        # [z_batch, 1, nz]\n",
    "        z = self.stochastic_encoder.reparametrize(mean, log_variance)\n",
    "\n",
    "        # [1, x_batch, nz]\n",
    "        mean, log_variance = mean.unsqueeze(0), log_variance.unsqueeze(0)\n",
    "\n",
    "        # (z_batch, x_batch, nz)\n",
    "\n",
    "        # (z_batch, x_batch)\n",
    "        log_density = -0.5 * (((z - mean) ** 2) / log_variance.exp()).sum(dim=-1) - \\\n",
    "            0.5 * (self.latent_dim * np.log(2 * np.pi) + log_variance.sum(-1))\n",
    "\n",
    "        # log q(z): aggregate posterior\n",
    "        # [z_batch]\n",
    "        log_qz = log_sum_exp(log_density, dim=1) - np.log(batch_size)\n",
    "\n",
    "        return (neg_entropy - log_qz.mean(-1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # old VAE\n",
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, hidden_dim, num_layers, embedding_weights, latent_dim, synthetic=False):\n",
    "#         super(VAE, self).__init__()\n",
    "#         self.encoder = Encoder(hidden_dim, num_layers, embedding_weights, synthetic)\n",
    "#         self.decoder = Decoder(hidden_dim, num_layers, embedding_weights, synthetic)\n",
    "#         self.latent_dim = latent_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.batch_first = True\n",
    "        \n",
    "#         self.hidden_to_mean = nn.Linear(2 * self.hidden_dim * num_layers, self.latent_dim, self.batch_first)\n",
    "#         self.hidden_to_logvar = nn.Linear(2 * self.hidden_dim * num_layers, self.latent_dim, self.batch_first)\n",
    "#         self.latent_to_hidden = nn.Linear(latent_dim, 2 * self.hidden_dim * num_layers, self.batch_first)\n",
    "#         if synthetic:          \n",
    "#             for param in self.parameters():\n",
    "#                 nn.init.uniform_(param, -0.01, 0.01)\n",
    "        \n",
    "#     def reparametrize(self, mean, log_variance):\n",
    "#         eps = torch.randn_like(mean)\n",
    "#         return mean + eps * torch.exp(0.5 * log_variance)\n",
    "        \n",
    "#     def encode(self, x, x_lens=None):\n",
    "#         batch_size, max_len, _ = x.shape\n",
    "#         hidden = self.encoder.init_hidden(batch_size)\n",
    "#         _, hidden = self.encoder.forward(x, hidden, x_lens)\n",
    "#         return hidden\n",
    "        \n",
    "#     def decode(self, hidden, x, x_lens=None, train=True):\n",
    "#         outputs, _ = self.decoder.forward(x, hidden, x_lens, train)\n",
    "#         return outputs\n",
    "\n",
    "#     def forward(self, x, x_lens=None):\n",
    "#         hidden = self.encode(x, x_lens)\n",
    "#         hidden_concatenated = torch.cat((hidden[0], hidden[1]), 2)\n",
    "        \n",
    "#         mean = self.hidden_to_mean(hidden_concatenated)\n",
    "        \n",
    "#         log_variance = self.hidden_to_logvar(hidden_concatenated)\n",
    "#         z = self.reparametrize(mean, log_variance)\n",
    "#         hidden = self.latent_to_hidden(z)\n",
    "        \n",
    "#         hidden = torch.split(hidden, self.hidden_dim, dim=2)\n",
    "#         outputs = self.decode(hidden, x, x_lens)\n",
    "#         return mean, log_variance, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(outputs, labels, mean, log_variance, annealing_args=None):\n",
    "    BCE = nn.CrossEntropyLoss(reduction='sum')(outputs, labels)\n",
    "    KLD = -0.5 * torch.sum(1 + log_variance - mean.pow(2) - log_variance.exp()) \n",
    "    if annealing_args is not None:\n",
    "        kl_weight = kl_annealing_weight(annealing_args['type'], annealing_args['step'], annealing_args['k'], annealing_args['first_step'])\n",
    "    else:\n",
    "        kl_weight = 1.0\n",
    "    BCE = BCE / mean.shape[1]  # divide by batch size\n",
    "    KLD /= mean.shape[1]\n",
    "    weighted_KLD = kl_weight * KLD\n",
    "    loss = BCE + weighted_KLD\n",
    "    return loss, BCE, KLD, weighted_KLD, kl_weight\n",
    "    \n",
    "def kl_annealing_weight(annealing_type, step, k, first_step):\n",
    "    if annealing_type == 'logistic':\n",
    "        return float(1/(1+np.exp(-k*(step-first_step))))\n",
    "    elif annealing_type == 'linear':\n",
    "        return min(1, step/first_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(outputs, labels, mean, log_variance, annealing_args=None):\n",
    "    BCE = nn.CrossEntropyLoss(reduction='none')(outputs, labels).view(mean.shape[1], -1).sum(-1)\n",
    "    KLD = -0.5 * (1 + log_variance - mean.pow(2) - log_variance.exp()).permute(1, 0, 2).squeeze(-1).squeeze(-1)\n",
    "    if annealing_args is not None:\n",
    "        kl_weight = kl_annealing_weight(annealing_args['type'], annealing_args['step'], annealing_args['k'], annealing_args['first_step'])\n",
    "    else:\n",
    "        kl_weight = 1.0\n",
    "    weighted_KLD = kl_weight * KLD\n",
    "    loss = BCE + weighted_KLD\n",
    "    return loss, BCE, KLD, weighted_KLD, kl_weight\n",
    "    \n",
    "def kl_annealing_weight(annealing_type, step, k, first_step):\n",
    "    if annealing_type == 'logistic':\n",
    "        return float(1/(1+np.exp(-k*(step-first_step))))\n",
    "    elif annealing_type == 'linear':\n",
    "        return min(1, step/first_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(value, dim=None, keepdim=False):\n",
    "    \"\"\"Numerically stable implementation of the operation\n",
    "    value.exp().sum(dim, keepdim).log() - copied from repo, we should change it\n",
    "    \"\"\"\n",
    "    if dim is not None:\n",
    "        m, _ = torch.max(value, dim=dim, keepdim=True)\n",
    "        value0 = value - m\n",
    "        if keepdim is False:\n",
    "            m = m.squeeze(dim)\n",
    "        return m + torch.log(torch.sum(torch.exp(value0), dim=dim, keepdim=keepdim))\n",
    "    else:\n",
    "        m = torch.max(value)\n",
    "        sum_exp = torch.sum(torch.exp(value - m))\n",
    "        return m + torch.log(sum_exp)\n",
    "\n",
    "def compute_true_posterior(latent_grid, vae, inputs, targets):\n",
    "    log_true_posterior = compute_true_log_posterior(latent_grid, vae, inputs, targets)\n",
    "    true_posterior = log_true_posterior.exp()\n",
    "    return true_posterior\n",
    "\n",
    "def compute_true_log_posterior(latent_grid, vae, inputs, targets):\n",
    "    latent_grid = latent_grid.unsqueeze(0).expand(inputs.shape[0], *latent_grid.size()).contiguous().permute(1, 0, 2)\n",
    "    \n",
    "    # Compute the true joint\n",
    "    log_true_joint = compute_true_joint(latent_grid, vae, inputs, targets)\n",
    "    \n",
    "    # Normalize by marginalizing z\n",
    "    log_true_posterior = log_true_joint - log_sum_exp(log_true_joint, dim=0, keepdim=True)\n",
    "    return log_true_posterior\n",
    "\n",
    "def compute_true_joint(latent_grid, vae, inputs, targets):\n",
    "    n_sample, batch_size, latent_dim = latent_grid.size()\n",
    "    seq_len = inputs.shape[1]\n",
    "    # Compute prior p(z)\n",
    "    normal = torch.distributions.normal.Normal(torch.zeros(latent_dim), torch.ones(latent_dim))\n",
    "    log_true_prior = normal.log_prob(latent_grid).sum(dim=-1)\n",
    "    \n",
    "    # Compute conditional p(x | z)\n",
    "    log_true_conditional = torch.zeros(latent_grid.size(0), latent_grid.size(1))\n",
    "    tensor_target_batch = torch.tensor(targets.reshape(-1), dtype=torch.long)\n",
    "    for i in range(latent_grid.size(0)):\n",
    "        hidden_concatenated = vae.latent_to_hidden(latent_grid[i]).unsqueeze(0)\n",
    "        hidden = torch.split(hidden_concatenated, vae.hidden_dim, dim=-1)\n",
    "        outputs = vae.decode(hidden, inputs, train=False)\n",
    "        log_true_conditional[i] = -nn.CrossEntropyLoss(reduction='none')(outputs, tensor_target_batch).view(batch_size, -1).sum(-1)\n",
    "        \n",
    "    # Compute joint p(x, z)\n",
    "    log_true_joint = log_true_prior + log_true_conditional\n",
    "    return log_true_joint\n",
    "\n",
    "def compute_true_posterior_mean(true_posterior, latent_grid):\n",
    "    return torch.mul(true_posterior.unsqueeze(2), latent_grid.unsqueeze(0)).sum(1)\n",
    "\n",
    "def generate_grid(lower, upper, step, dim=2):\n",
    "    line = torch.arange(lower, upper, step)\n",
    "    total_points = line.size(0)\n",
    "    if dim == 2:\n",
    "        z1 = line.unsqueeze(1).repeat(1, total_points).view(-1)\n",
    "        z2 = line.repeat(total_points)\n",
    "        return torch.cat((z1.unsqueeze(-1), z2.unsqueeze(-1)), dim=-1)\n",
    "    elif dim == 1:\n",
    "        return line.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_space(step, latent_size, vae, tracked_inputs, tracked_targets, lim=3, iteration=None):\n",
    "    latent_grid = generate_grid(-5, 5, step, latent_size)\n",
    "    true_posterior = compute_true_posterior(latent_grid, vae, tracked_inputs, tracked_targets)\n",
    "    true_mean = compute_true_posterior_mean(true_posterior.t(), latent_grid)\n",
    "    vae.eval()\n",
    "    approximate_mean, _, _ = vae.forward(tracked_inputs)\n",
    "    vae.train()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(true_mean.detach().numpy(), approximate_mean.detach().numpy(), marker='x')\n",
    "    plt.xlim(-lim, lim)\n",
    "    plt.ylim(-lim, lim)\n",
    "    plt.xlabel(\"true postrior mean\")\n",
    "    plt.ylabel(\"approximate posterior mean\")\n",
    "    if iteration is not None:\n",
    "        plt.title(\"iteration {0}\".format(iteration))\n",
    "    plt.show()\n",
    "\n",
    "def plot_kl(kl_terms, kl_weights):\n",
    "    plot_step = 10\n",
    "    x_axis = np.arange(len(kl_terms[::plot_step])) * plot_step\n",
    "    fig, ax1 = plt.subplots(figsize=(8,4))\n",
    "    ax1.plot(x_axis, kl_terms[::plot_step], label=\"KL term value\")\n",
    "    ax1.set_xlabel(\"iteration\")\n",
    "    ax1.set_ylabel(\"KL term\")\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x_axis, kl_weights[::plot_step], color=\"orange\", label=\"KL weight\")\n",
    "    ax2.set_ylabel(\"KL weight\")\n",
    "    ax2.set_ylim(0,1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_losses(total_loss, ce_loss, kl_loss):\n",
    "    plot_step = 10\n",
    "    x_axis = np.arange(len(total_loss[::plot_step])) * plot_step\n",
    "    total_loss = np.array(total_loss[::plot_step])\n",
    "    kl_loss = np.array(kl_loss[::plot_step])\n",
    "    fig, ax1 = plt.subplots(figsize=(8,4))\n",
    "    plt.fill_between(x_axis, np.zeros(len(x_axis)), total_loss, label=\"total loss\")\n",
    "    plt.fill_between(x_axis, np.zeros(len(x_axis)), kl_loss, label=\"kl loss\")\n",
    "    plt.xlabel(\"loss\")\n",
    "    plt.ylabel(\"iteration\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(vae, inputs, targets, validation_data, epochs, vocab_size, hidden_size, latent_size, input_lens=None, synthetic=False, \n",
    "          num_layers=1, step=1.0, learning_rate=0.001, tracked_inputs=None, tracked_targets=None, annealing_args=None, \n",
    "          is_aggressive=False, plot=False, plot_lim=1.5, verbose=True):\n",
    "    \n",
    "    enc_optimizer = torch.optim.Adam(vae.encoder.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "    stoch_enc_optimizer = torch.optim.Adam(vae.stochastic_encoder.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "    stoch_dec_optimizer = torch.optim.Adam(vae.stochastic_decoder.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "    dec_optimizer = torch.optim.Adam(vae.decoder.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "#    vae_optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "    \n",
    "    if annealing_args is not None:\n",
    "        kl_terms = []\n",
    "        kl_weights = []\n",
    "\n",
    "    iteration = 0\n",
    "    total_losses = []\n",
    "    ce_losses = []\n",
    "    kl_losses = []\n",
    "    \n",
    "    if plot:\n",
    "        plot_mean_space(step, latent_size, vae, tracked_inputs, tracked_targets, lim=plot_lim, iteration=iteration)\n",
    "    \n",
    "    previous_mi = -1\n",
    "        \n",
    "    for epoch in range(epochs):        \n",
    "        for i in np.random.permutation(len(inputs)):\n",
    "            \n",
    "            inner_iter = 1\n",
    "            random_i = i\n",
    "            \n",
    "            burn_num_words = 0\n",
    "            burn_pre_loss = 1e4\n",
    "            burn_cur_loss = 0\n",
    "            while is_aggressive and inner_iter < 100:\n",
    "                x = inputs[random_i]\n",
    "                y = torch.tensor(targets[random_i].reshape(-1), dtype=torch.long)\n",
    "                x_lens = input_lens[random_i] if not synthetic else None\n",
    "                \n",
    "                enc_optimizer.zero_grad()\n",
    "                stoch_enc_optimizer.zero_grad()\n",
    "                stoch_dec_optimizer.zero_grad()\n",
    "                dec_optimizer.zero_grad()\n",
    "                \n",
    "                burn_batch_size, burn_sents_len, _ = x.shape\n",
    "                burn_num_words += burn_sents_len * burn_batch_size\n",
    "              \n",
    "                mean, log_variance, outputs = vae(x, x_lens=x_lens)\n",
    "                if not synthetic:\n",
    "                    mask = (y < padding_index)\n",
    "                    outputs = outputs[mask]\n",
    "                    y = y[mask]\n",
    "    \n",
    "                loss_summary = loss_function(outputs, y, mean, log_variance, annealing_args=annealing_args)\n",
    "                \n",
    "                loss = loss_summary[0]\n",
    "                burn_cur_loss += loss.sum().item()\n",
    "                \n",
    "                loss = loss.mean(dim=-1)\n",
    "                loss.backward()\n",
    "                \n",
    "                clip_grad_norm_(vae.parameters(), 5.0)\n",
    "                \n",
    "                stoch_enc_optimizer.step()\n",
    "                enc_optimizer.step()\n",
    "                random_i = np.random.randint(0, len(inputs)- 1)\n",
    "                if inner_iter % 15 == 0:\n",
    "                    burn_cur_loss = burn_cur_loss / burn_num_words\n",
    "                    if burn_pre_loss - burn_cur_loss < 0:\n",
    "                        break\n",
    "                    burn_pre_loss = burn_cur_loss\n",
    "                    burn_cur_loss = burn_num_words = 0\n",
    "                inner_iter += 1\n",
    "              \n",
    "            x = inputs[i]\n",
    "            y = torch.tensor(targets[i].reshape(-1), dtype=torch.long)\n",
    "            x_lens = input_lens[i] if not synthetic else None  \n",
    "            \n",
    "            mean, log_variance, outputs = vae(x, x_lens=x_lens)\n",
    "            if not synthetic:\n",
    "                mask = (y < padding_index)\n",
    "                outputs = outputs[mask]\n",
    "                y = y[mask]\n",
    "\n",
    "            loss_summary = loss_function(outputs, y, mean, log_variance, annealing_args=annealing_args)\n",
    "#             total_losses.append(loss_summary[0].data.item())\n",
    "#             ce_losses.append(loss_summary[1].data.item())\n",
    "#             kl_losses.append(loss_summary[3].data.item())\n",
    "            \n",
    "            loss = loss_summary[0]\n",
    "                \n",
    "            loss = loss.mean(dim=-1)\n",
    "            \n",
    "#             if annealing_args is not None:\n",
    "#                 kl_terms.append(loss_summary[2].data.item())\n",
    "#                 kl_weights.append(loss_summary[4])     \n",
    "            \n",
    "            enc_optimizer.zero_grad()\n",
    "            stoch_enc_optimizer.zero_grad()\n",
    "            stoch_dec_optimizer.zero_grad()\n",
    "            dec_optimizer.zero_grad()\n",
    "#             vae_optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            clip_grad_norm_(vae.parameters(), 5.0)\n",
    "            dec_optimizer.step()\n",
    "            stoch_dec_optimizer.step()\n",
    "            if not is_aggressive:\n",
    "                stoch_enc_optimizer.step()\n",
    "                enc_optimizer.step()\n",
    "            #vae_optimizer.step()\n",
    "\n",
    "            if (iteration % 100 == 0) and verbose:\n",
    "                print('epoch {} iteration {} loss {:.3f} CE {:.3f} KL {:.3f} weighted KL: {:.3f} weight {:.3f}'.format(epoch+1, \n",
    "                            iteration, loss, loss_summary[1].mean(dim=-1).data.item(), \\\n",
    "                            loss_summary[2].mean(dim=-1).data.item(), \\\n",
    "                            loss_summary[3].mean(dim=-1).data.item(), loss_summary[4]))\n",
    "\n",
    "            iteration += 1\n",
    "            \n",
    "            if annealing_args is not None:\n",
    "                annealing_args['step'] = iteration\n",
    "        \n",
    "        if is_aggressive:\n",
    "            vae.eval()\n",
    "            current_mi = calc_mi(vae, validation_data)\n",
    "            vae.train()\n",
    "            print('current_mi:', current_mi)\n",
    "            if current_mi - previous_mi < 0:\n",
    "                is_aggressive = False\n",
    "                print(\"STOP AGGRESSIVE\")\n",
    "\n",
    "            previous_mi = current_mi\n",
    "                \n",
    "        if (epoch % 1 == 0) and plot:\n",
    "            plot_mean_space(step, latent_size, vae, tracked_inputs, tracked_targets, lim=plot_lim, iteration=iteration)\n",
    "       \n",
    "    \n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}\\n'\n",
    "               .format(epoch + 1, epochs, loss.item(), np.exp(loss.item())))\n",
    "    \n",
    "    if annealing_args is not None:\n",
    "        plot_kl(kl_terms, kl_weights)\n",
    "    plot_losses(total_losses, ce_losses, kl_losses)\n",
    "    \n",
    "def calc_mi(model, test_data_batch):\n",
    "    mi = 0\n",
    "    num_examples = 0\n",
    "    for batch_data in test_data_batch:\n",
    "        batch_size = batch_data.shape[0]\n",
    "        num_examples += batch_size\n",
    "        mutual_info = model.calc_mi(batch_data)\n",
    "        mi += mutual_info * batch_size\n",
    "\n",
    "    return mi / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-eadcd14e522e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m train(vae, inputs, targets, val_inputs, epochs, vocab_size, hidden_size, latent_size, plot=True, learning_rate=learning_rate,\n\u001b[1;32m---> 15\u001b[1;33m       synthetic=True, step=step, tracked_inputs=tracked_inputs, tracked_targets=tracked_targets, plot_lim=1.5)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-5dcef7a1871e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(vae, inputs, targets, validation_data, epochs, vocab_size, hidden_size, latent_size, input_lens, synthetic, num_layers, step, learning_rate, tracked_inputs, tracked_targets, annealing_args, is_aggressive, plot, plot_lim, verbose)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprevious_mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# without annealing\n",
    "vocab_size = 1000\n",
    "hidden_size = 50\n",
    "embedding_size = 50\n",
    "latent_size = 1\n",
    "num_layers = 1\n",
    "step = 0.25\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "embedding_weights = nn.Embedding(vocab_size, embedding_size).weight\n",
    "vae = VAE(hidden_size, num_layers, embedding_weights, latent_size, synthetic=True)\n",
    "\n",
    "train(vae, inputs, targets, val_inputs, epochs, vocab_size, hidden_size, latent_size, plot=True, learning_rate=learning_rate,\n",
    "      synthetic=True, step=step, tracked_inputs=tracked_inputs, tracked_targets=tracked_targets, plot_lim=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#with annealing\n",
    "vocab_size = 1000\n",
    "hidden_size = 50\n",
    "embedding_size = 50\n",
    "latent_size = 1\n",
    "num_layers = 1\n",
    "step = 0.25\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "vae = VAE(hidden_size, num_layers, embedding_weights, latent_size, synthetic=True)\n",
    "\n",
    "annealing_args = {'type':'logistic', 'step':0, 'k':0.0025, 'first_step':2500}\n",
    "\n",
    "train(vae, inputs, targets, val_inputs, epochs, vocab_size, hidden_size, latent_size, plot=True, learning_rate=learning_rate,\n",
    "      synthetic=True, step=step, plot_lim=3, annealing_args=annealing_args, tracked_inputs=tracked_inputs, \n",
    "      tracked_targets=tracked_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 iteration 0 loss 62.180 CE 62.180 KL 0.000 weighted KL: 0.000 weight 1.000\n",
      "epoch 1 iteration 100 loss 46.218 CE 46.218 KL 0.000 weighted KL: 0.000 weight 1.000\n",
      "epoch 1 iteration 200 loss 43.401 CE 43.382 KL 0.018 weighted KL: 0.018 weight 1.000\n",
      "epoch 1 iteration 300 loss 34.366 CE 33.282 KL 1.083 weighted KL: 1.083 weight 1.000\n",
      "epoch 1 iteration 400 loss 31.306 CE 29.813 KL 1.493 weighted KL: 1.493 weight 1.000\n",
      "epoch 1 iteration 500 loss 41.229 CE 39.753 KL 1.476 weighted KL: 1.476 weight 1.000\n",
      "epoch 1 iteration 600 loss 34.690 CE 33.192 KL 1.497 weighted KL: 1.497 weight 1.000\n",
      "epoch 1 iteration 700 loss 35.933 CE 34.389 KL 1.544 weighted KL: 1.544 weight 1.000\n",
      "epoch 1 iteration 800 loss 32.431 CE 30.696 KL 1.734 weighted KL: 1.734 weight 1.000\n",
      "epoch 1 iteration 900 loss 32.792 CE 31.283 KL 1.509 weighted KL: 1.509 weight 1.000\n",
      "current_mi: 2.7813310928344728\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 39.7861, Perplexity: 190058805975092864.00\n",
      "\n",
      "epoch 2 iteration 1000 loss 34.640 CE 33.069 KL 1.571 weighted KL: 1.571 weight 1.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-677caf5dc1df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m train(vae, inputs, targets, val_inputs, epochs, vocab_size, hidden_size, latent_size, plot=True, learning_rate=learning_rate,\n\u001b[1;32m---> 15\u001b[1;33m       synthetic=True, step=step, tracked_inputs=tracked_inputs, tracked_targets=tracked_targets, plot_lim=1.5, is_aggressive=True)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-77579a1cfe33>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(vae, inputs, targets, validation_data, epochs, vocab_size, hidden_size, latent_size, input_lens, synthetic, num_layers, step, learning_rate, tracked_inputs, tracked_targets, annealing_args, is_aggressive, plot, plot_lim, verbose)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# aggresive training\n",
    "vocab_size = 1000\n",
    "hidden_size = 50\n",
    "embedding_size = 50\n",
    "latent_size = 1\n",
    "num_layers = 1\n",
    "step = 0.25\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "embedding_weights = nn.Embedding(vocab_size, embedding_size).weight\n",
    "vae = VAE(hidden_size, num_layers, embedding_weights, latent_size, synthetic=True)\n",
    "\n",
    "train(vae, inputs, targets, val_inputs, epochs, vocab_size, hidden_size, latent_size, plot=True, learning_rate=learning_rate,\n",
    "      synthetic=True, step=step, tracked_inputs=tracked_inputs, tracked_targets=tracked_targets, plot_lim=1.5, is_aggressive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Word2Vec word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 500\n",
    "num_epochs_to_train = 10\n",
    "\n",
    "word2vec_model = Word2Vec(train_data, min_count=1, size=embedding_size, window=5)\n",
    "word2vec_model.train(train_data, epochs=num_epochs_to_train, total_examples=word2vec_model.corpus_count)\n",
    "\n",
    "word2vec_model.wv.most_similar(\"stocks\")\n",
    "# word2vec_model.wv['credit']\n",
    "\n",
    "vocabulary_size = len(word2vec_model.wv.vocab)\n",
    "print(\"size of the vocabulary:\", vocabulary_size)\n",
    "word2vec_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define RNNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLM(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_size, hidden_size, num_layers, embedding_weights):\n",
    "        super(RNNLM, self).__init__()\n",
    "        self.embed = nn.Embedding.from_pretrained(embedding_weights)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocabulary_size)\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "    def forward(self, x, hidden, x_lens, train=True):\n",
    "        batch_size, max_len, _ = x.shape\n",
    "        embedding_dim = self.embedding_size\n",
    "\n",
    "        x = self.embed(torch.tensor(x, dtype=torch.long)).view(batch_size, max_len, embedding_dim)\n",
    "        if train:\n",
    "            x_lens = torch.tensor(x_lens, dtype=torch.long)\n",
    "            x = pack_padded_sequence(x, x_lens, batch_first=True)\n",
    "\n",
    "        out, hidden = self.lstm(x.float(), hidden) \n",
    "        \n",
    "        if train:\n",
    "            out, output_lens = pad_packed_sequence(out, batch_first=True, total_length=max_sentence_length-1)\n",
    "\n",
    "        out = out.reshape(out.size(0)*out.size(1), out.size(2))\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict with RNNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 100\n",
    "output_size = 100\n",
    "hidden_size = 50\n",
    "\n",
    "batch_size = 20\n",
    "use_first_k = 500\n",
    "padding_index = vocabulary_size\n",
    "train_batches, train_targets, train_sentence_lens = get_batches(train_data[:use_first_k], train_data_padded[:use_first_k], \n",
    "                                                                batch_size, padding_index, word2vec_model)\n",
    "\n",
    "# make the word embeddings into a pythorch tensor\n",
    "embedding_weights = word2vec_model.wv.vectors\n",
    "embedding_weights = np.vstack((embedding_weights, np.zeros((1,embedding_size))))  # add zero vector for <pad>\n",
    "embedding_weights = torch.tensor(embedding_weights)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_layers = 1\n",
    "epochs = 10\n",
    "\n",
    "model = RNNLM(vocabulary_size, embedding_size, hidden_size, num_layers, embedding_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hidden = (torch.zeros(num_layers, batch_size, hidden_size), torch.zeros(num_layers, batch_size, hidden_size))\n",
    "    for i in range(len(train_batches)):\n",
    "        x = train_batches[i]\n",
    "        x_lens = train_sentence_lens[i]\n",
    "        y = torch.tensor(train_targets[i].reshape(-1), dtype=torch.long)   \n",
    "        h, c = hidden\n",
    "        h = h.detach()\n",
    "        c = c.detach()\n",
    "        hidden = (h, c)\n",
    "    \n",
    "        outputs, hidden = model(x, hidden, x_lens)\n",
    "        \n",
    "        mask = (y < padding_index)\n",
    "        loss = nn.CrossEntropyLoss()(outputs[mask], y[mask])\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'\n",
    "               .format(epoch + 1, epochs, loss.item(), np.exp(loss.item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "test_sentences = [\"he could see\"]\n",
    "sentence, _ = tokenize_sentence(test_sentences[0], max_sentence_length)\n",
    "sentence = sentence[:-1]\n",
    "word_indexes = np.array([word2vec_model.wv.vocab[word].index for word in sentence]).reshape(1, len(sentence), 1)\n",
    "print(word_indexes.shape)\n",
    "\n",
    "hidden = (torch.zeros(1, 1, hidden_size), torch.zeros(1, 1, hidden_size))\n",
    "h, c = hidden\n",
    "h = h.detach()\n",
    "c = c.detach()\n",
    "hidden = (h, c)\n",
    "\n",
    "outputs, hidden = model(word_indexes, hidden, x_lens, train=False)\n",
    "softmax_outputs = F.softmax(outputs, dim=1).detach().numpy()\n",
    "last_word = softmax_outputs[-1,:]\n",
    "predicted_next_word_idx = np.random.choice(range(len(last_word)), p=last_word)\n",
    "print(\"Argmax: \", word2vec_model.wv.index2word[np.argmax(last_word)])\n",
    "print(\"Next word: \", word2vec_model.wv.index2word[predicted_next_word_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
