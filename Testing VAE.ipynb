{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions.normal as normal\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "from vae_util import Util\n",
    "from vae import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Util\n"
     ]
    }
   ],
   "source": [
    "util = Util()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_total_epoch_losses_vae = pickle.load(open(\"results-vae/yelp_total_epoch_losses_vae.pkl\", \"rb\"))\n",
    "yelp_total_kl_losses_vae = pickle.load(open(\"results-vae/yelp_total_kl_losses_vae.pkl\", \"rb\"))\n",
    "yelp_total_mi_vae = pickle.load(open(\"results-vae/yelp_total_mi_vae.pkl\", \"rb\"))\n",
    "\n",
    "yelp_val_total_epoch_losses_vae = pickle.load(open(\"results-vae/yelp_val_total_epoch_losses_vae.pkl\", \"rb\"))\n",
    "yelp_val_total_kl_losses_vae = pickle.load(open(\"results-vae/yelp_val_total_kl_losses_vae.pkl\", \"rb\"))\n",
    "yelp_val_total_mi_vae = pickle.load(open(\"results-vae/yelp_val_total_mi_vae.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[788.98010263 639.25411682]\n",
      "[ 7.93675241 25.53156433]\n",
      "[2.73162553 2.86714189]\n",
      "[919.79012532 851.97334471]\n",
      "[ 9.12696004 28.56146727]\n",
      "[2.77312319 2.73645301]\n",
      "Loaded Util\n"
     ]
    }
   ],
   "source": [
    "print(yelp_total_epoch_losses_vae)\n",
    "print(yelp_total_kl_losses_vae)\n",
    "print(yelp_total_mi_vae)\n",
    "\n",
    "print(yelp_val_total_epoch_losses_vae)\n",
    "print(yelp_val_total_kl_losses_vae)\n",
    "print(yelp_val_total_mi_vae)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "util = Util()\n",
    "\n",
    "\n",
    "\n",
    "embedding_size = 512\n",
    "word2vec_model_name = \"word2vec_yelp.model\"\n",
    "word2vec_yelp = Word2Vec.load(word2vec_model_name)\n",
    "embedding_weights = word2vec_yelp.wv.vectors\n",
    "embedding_weights = np.vstack((embedding_weights, np.zeros((1,embedding_size))))  # add zero vector for <pad>\n",
    "embedding_weights = torch.tensor(embedding_weights, device=device)\n",
    "\n",
    "batch_size = 16\n",
    "vocabulary_size = len(word2vec_yelp.wv.vocab)\n",
    "padding_index = vocabulary_size\n",
    "hidden_size = 1024\n",
    "latent_size = 1\n",
    "num_layers = 1\n",
    "step = 0.25\n",
    "learning_rate = 0.01\n",
    "epochs = 2\n",
    "max_sentence_length = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (embed): Embedding(19840, 512)\n",
       "    (lstm): LSTM(512, 1024, batch_first=True)\n",
       "  )\n",
       "  (stochastic_encoder): StochasticEncoder(\n",
       "    (hidden_to_mean): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (hidden_to_logvar): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  )\n",
       "  (stochastic_decoder): StochasticDecoder(\n",
       "    (latent_to_hidden): Linear(in_features=1, out_features=2048, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embed): Embedding(19840, 512)\n",
       "    (lstm): LSTM(512, 1024, batch_first=True)\n",
       "    (linear): Linear(in_features=1024, out_features=19840, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE(hidden_size, num_layers, embedding_weights, latent_size, max_sentence_length, device, synthetic=True).to(device)\n",
    "model.load_state_dict(torch.load(\"results-vae/yelp-vae.pwf\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_test_data_original, yelp_test_data_padded = util.load_data(\"yelp_data/yelp.test.txt\", max_sentence_length, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_test_inputs, yelp_test_targets, yelp_test_lengths = \\\n",
    "                util.get_batches_text(yelp_test_data_original, yelp_test_data_padded, batch_size, padding_index, word2vec_yelp, '_unk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, kl, ppl, mutual_info = util.test_vae(model, yelp_test_inputs[:10], yelp_test_targets[:10], yelp_test_lengths[:10], padding_index, max_sentence_length, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873.6742292404175 26.759928703308105 4.688080802596484e+84 2.7549392700195314\n"
     ]
    }
   ],
   "source": [
    "print(loss, kl, ppl, mutual_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
