{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1099c6f30>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/eliisabethein/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import MWETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sentences: 42068\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = TweetTokenizer(preserve_case=False)\n",
    "tok = MWETokenizer([('<', 'unk', '>')], separator = '')\n",
    "\n",
    "train_data = []\n",
    "vocabulary = []\n",
    "\n",
    "with open(\"data/ptb.train.txt\") as f:\n",
    "    total_sentences = 0\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip()\n",
    "        s = word_tokenize(line)\n",
    "        s = tok.tokenize(s)\n",
    "        s = ['<sos>'] + s + ['<eos>']\n",
    "        total_sentences += 1\n",
    "        train_data.append(s)\n",
    "        vocabulary += s\n",
    "\n",
    "vocabulary = sorted(list(set(vocabulary)))\n",
    "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
    "\n",
    "print(\"total sentences:\", total_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#', '$', '&', \"'\", \"'80s\", \"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", '.', '10-year', '100-share', '12-month', '12-year', '13-week', '13th', '14-year-old', '190-point', '190.58-point', '1920s', '1930s', '1950s', '1960s', '1970s', '1980s', '1990s', '19th', '1\\\\/2-year', '2-for-1', '20-year', '20th', '24-hour', '26-week', '30-day', '30-share', '30-year', '300-a-share', '300-day', '40-year-old', '45-year-old', '500-stock', '52-week', '<eos>', '<sos>', '<unk>', 'N', '\\\\*', '\\\\*\\\\*', 'a', 'a.', 'a.c.', 'a.g.', 'a.m', 'a.m.', 'a.p', 'ab', 'aba', 'abandon', 'abandoned', 'abandoning', 'abbie', 'abc', 'ability', 'able', 'abm', 'aboard', 'abolish', 'abolished', 'aborted', 'abortion', 'abortion-rights', 'abortions', 'about', 'above', 'abrams', 'abramson', 'abroad', 'abrupt', 'abruptly', 'absence', 'absolutely', 'absorb', 'absorbed', 'absurd', 'abundant', 'abuse', 'abused', 'abuses', 'academic', 'academy', 'acadia', 'accelerate', 'accelerated', 'accelerating', 'acceleration', 'accept', 'acceptable', 'acceptance']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66894081, 97292600)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model1 = Word2Vec(train_data, min_count=1, size=100, window=5)\n",
    "model1.train(train_data, len(train_data), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shares', 0.6191723346710205),\n",
       " ('stocks', 0.5622472763061523),\n",
       " ('equity', 0.5172011852264404),\n",
       " ('share', 0.49241119623184204),\n",
       " ('mercantile', 0.4393764138221741),\n",
       " ('junk-bond', 0.42797455191612244),\n",
       " ('plunge', 0.4248238801956177),\n",
       " ('junk', 0.4115976393222809),\n",
       " ('listed', 0.4005429446697235),\n",
       " ('bancroft', 0.3902745246887207)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.most_similar(\"stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f.', 0.44190406799316406),\n",
       " ('w.', 0.42585569620132446),\n",
       " ('s.', 0.4127725660800934),\n",
       " ('h.', 0.3979629874229431),\n",
       " ('mich.', 0.3972141742706299),\n",
       " ('n.j.', 0.3921316862106323),\n",
       " ('g.', 0.3899410665035248),\n",
       " ('ben', 0.3676188588142395),\n",
       " ('l.', 0.36253631114959717),\n",
       " ('neal', 0.3608734607696533)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.most_similar(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('debt', 0.4402936100959778),\n",
       " ('loans', 0.42133408784866333),\n",
       " ('financial', 0.4157423973083496),\n",
       " ('payment', 0.39422550797462463),\n",
       " ('coverage', 0.3736409842967987),\n",
       " ('deposit', 0.3729313910007477),\n",
       " ('write-downs', 0.35258758068084717),\n",
       " ('financing', 0.35087263584136963),\n",
       " ('receivables', 0.3490930497646332),\n",
       " ('asset-backed', 0.3486577272415161)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.most_similar(\"credit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.7747359e-01,  2.9686937e+00,  2.6501117e+00,  3.0834761e+00,\n",
       "        2.8429997e+00, -4.1582528e-01, -2.1958084e-01, -8.1865644e-01,\n",
       "       -7.4580342e-01, -2.1322248e+00,  5.0131792e-01,  2.5824676e+00,\n",
       "        1.0857420e+00, -3.9138109e-03, -1.7516010e+00,  1.2858166e+00,\n",
       "       -7.7668393e-01, -1.9802961e+00,  1.4377120e+00,  5.3491254e+00,\n",
       "        5.4552820e-02, -2.5157261e+00, -1.5339265e+00,  2.3392994e+00,\n",
       "       -2.4587250e+00,  1.5426154e+00, -2.6625531e+00, -1.0871540e+00,\n",
       "       -3.0938814e+00,  5.2244955e-01,  4.6642222e+00, -1.9233023e+00,\n",
       "        2.1165483e+00,  4.5259926e-01,  2.7725346e+00, -2.7302454e+00,\n",
       "        5.8359828e-02,  9.1397029e-01,  1.1368673e+00,  4.3198762e+00,\n",
       "       -9.0990670e-02,  1.1243713e+00, -1.6051178e+00,  4.9419980e+00,\n",
       "        6.8594003e-01,  1.2052360e+00,  2.9179436e-01, -2.6810260e+00,\n",
       "       -6.8622929e-01,  2.9879980e+00, -1.6163086e+00, -9.4656420e-01,\n",
       "       -6.3592833e-01,  6.2702984e-01,  2.0392424e-01,  2.7440622e+00,\n",
       "        3.7823210e+00, -6.4470285e-01, -1.5013463e+00,  1.0443970e+00,\n",
       "        2.9590847e+00, -3.3231151e-01,  3.1714218e+00, -1.3306912e+00,\n",
       "       -2.3956756e-01,  1.6482706e+00,  9.0018839e-02, -1.4465727e+00,\n",
       "        7.2829431e-01,  1.6886508e+00,  2.7107301e+00, -3.6760018e+00,\n",
       "       -1.4163026e+00,  5.3451413e-01,  1.5303694e+00,  3.8848782e-01,\n",
       "       -7.4584955e-01, -2.4029286e+00, -4.9559480e-01,  2.5916626e+00,\n",
       "       -1.1640162e+00,  1.2868423e+00, -3.2596231e+00,  1.5055341e+00,\n",
       "       -2.2260485e+00,  1.4073596e+00, -2.7722549e+00,  2.4529579e+00,\n",
       "       -5.2562833e-01,  5.5294561e-01,  1.0945362e+00, -2.6181953e+00,\n",
       "       -2.8044894e-02,  2.9919279e+00,  1.4691957e+00, -5.2082974e-01,\n",
       "       -8.3411485e-01,  2.9911190e-01, -1.3843997e+00,  1.4359474e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(vocabulary)\n",
    "input_size = 100\n",
    "output_size = 100\n",
    "hidden_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_word = 'money'\n",
    "embedding_vec = model1.wv[input_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the word embeddings into a pythorch tensor\n",
    "weights = torch.FloatTensor(model1.wv.vectors)\n",
    "\n",
    "# NN MODEL\n",
    "embedded = nn.Embedding.from_pretrained(weights) #input layer\n",
    "lstm = nn.LSTM(input_size, hidden_size, num_layers=1) #lstm layer\n",
    "out = nn.Linear(hidden_size, output_size)\n",
    "softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "# loss_function = nn.NLLLoss()\n",
    "# optimizer = optim.SGD( lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = train_data[2]\n",
    "input_idx = [model1.wv.vocab[x].index for x in input_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word: <sos>\n",
      "predicted_class: after\n",
      "input word: mr.\n",
      "predicted_class: other\n",
      "input word: <unk>\n",
      "predicted_class: he\n",
      "input word: is\n",
      "predicted_class: into\n",
      "input word: chairman\n",
      "predicted_class: only\n",
      "input word: of\n",
      "predicted_class: he\n",
      "input word: <unk>\n",
      "predicted_class: he\n",
      "input word: n.v.\n",
      "predicted_class: into\n",
      "input word: the\n",
      "predicted_class: he\n",
      "input word: dutch\n",
      "predicted_class: he\n",
      "input word: publishing\n",
      "predicted_class: over\n",
      "input word: group\n",
      "predicted_class: <eos>\n",
      "input word: <eos>\n",
      "predicted_class: he\n"
     ]
    }
   ],
   "source": [
    "# intialise first hidden state\n",
    "(hidden, cell) = (torch.zeros(1, 1, hidden_size), torch.zeros(1, 1, hidden_size))\n",
    "\n",
    "for idx in input_idx:\n",
    "    print(\"input word:\", model1.wv.index2word[idx])\n",
    "    output = embedded(torch.tensor([idx], dtype=torch.long)).view(1, 1, 100)\n",
    "    output, (hidden, cell) = lstm(output, (hidden, cell))\n",
    "    output = softmax(out(output[0]))\n",
    "    predicted_idx = np.argmax(output.detach().numpy())\n",
    "    print(\"predicted_class: {0}\".format(model1.wv.index2word[predicted_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
